<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/amazonaws/services/sagemaker/sparksdk/algorithms/LinearLearnerSageMakerEstimator.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier;'>1 <span style=''>/*
</span>2 <span style=''> * Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.
</span>3 <span style=''> *
</span>4 <span style=''> * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;).
</span>5 <span style=''> * You may not use this file except in compliance with the License.
</span>6 <span style=''> * A copy of the License is located at
</span>7 <span style=''> *
</span>8 <span style=''> *   http://aws.amazon.com/apache2.0/
</span>9 <span style=''> *
</span>10 <span style=''> * or in the &quot;license&quot; file accompanying this file. This file is distributed
</span>11 <span style=''> * on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
</span>12 <span style=''> * express or implied. See the License for the specific language governing
</span>13 <span style=''> * permissions and limitations under the License.
</span>14 <span style=''> */
</span>15 <span style=''>
</span>16 <span style=''>package com.amazonaws.services.sagemaker.sparksdk.algorithms
</span>17 <span style=''>
</span>18 <span style=''>import com.amazonaws.regions.DefaultAwsRegionProviderChain
</span>19 <span style=''>import com.amazonaws.services.s3.{AmazonS3, AmazonS3ClientBuilder}
</span>20 <span style=''>import com.amazonaws.services.securitytoken.{AWSSecurityTokenService, AWSSecurityTokenServiceClientBuilder}
</span>21 <span style=''>
</span>22 <span style=''>import org.apache.spark.ml.param._
</span>23 <span style=''>import org.apache.spark.ml.util.Identifiable
</span>24 <span style=''>import org.apache.spark.sql.Row
</span>25 <span style=''>import org.apache.spark.sql.types.StructType
</span>26 <span style=''>
</span>27 <span style=''>import com.amazonaws.services.sagemaker.{AmazonSageMaker, AmazonSageMakerClientBuilder}
</span>28 <span style=''>import com.amazonaws.services.sagemaker.model.{S3DataDistribution, TrainingInputMode}
</span>29 <span style=''>import com.amazonaws.services.sagemaker.sparksdk._
</span>30 <span style=''>import com.amazonaws.services.sagemaker.sparksdk.EndpointCreationPolicy.EndpointCreationPolicy
</span>31 <span style=''>import com.amazonaws.services.sagemaker.sparksdk.transformation.{RequestRowSerializer, ResponseRowDeserializer}
</span>32 <span style=''>import com.amazonaws.services.sagemaker.sparksdk.transformation.deserializers.{LinearLearnerBinaryClassifierProtobufResponseRowDeserializer, LinearLearnerRegressorProtobufResponseRowDeserializer}
</span>33 <span style=''>import com.amazonaws.services.sagemaker.sparksdk.transformation.serializers.ProtobufRequestRowSerializer
</span>34 <span style=''>
</span>35 <span style=''>/**
</span>36 <span style=''>  * Common params for [[LinearLearnerSageMakerEstimator]] with accessors
</span>37 <span style=''>  */
</span>38 <span style=''>private[algorithms] trait BinaryClassifierParams extends LinearLearnerParams {
</span>39 <span style=''>  /**
</span>40 <span style=''>    * Pick the model with best criteria from the validation dataset for predictor_type is
</span>41 <span style=''>    * &quot;binary_classifier&quot;. Supported options: &quot;accuracy&quot;, &quot;f1&quot;, &quot;precision_at_target_recall&quot;,
</span>42 <span style=''>    * &quot;recall_at_target_precision&quot; and &quot;cross_entropy_loss&quot;.
</span>43 <span style=''>    * accuracy: model with highest accuracy
</span>44 <span style=''>    * f1: model with highest f1 score
</span>45 <span style=''>    * precision_at_target_recall: model with highest precision at a given recall target
</span>46 <span style=''>    * recall_at_target_precision: model with highest recall at a given precision target
</span>47 <span style=''>    * cross_entropy_loss: model with lowest cross entropy loss
</span>48 <span style=''>    * Default: &quot;accuracy&quot;.
</span>49 <span style=''>    */
</span>50 <span style=''>  val binaryClassifierModelSelectionCriteria: Param[String] = </span><span style='background: #AEF1AE'>new Param(this,
</span>51 <span style=''></span><span style='background: #AEF1AE'>    &quot;binary_classifier_model_selection_criteria&quot;,
</span>52 <span style=''></span><span style='background: #AEF1AE'>    &quot;Pick the model with best criteria from the validation dataset for predictor_type = &quot; +
</span>53 <span style=''></span><span style='background: #AEF1AE'>      &quot;binary_classifier. &quot; +
</span>54 <span style=''></span><span style='background: #AEF1AE'>      &quot;Supported options: 'accuracy', 'f1', 'precision_at_target_recall',&quot; +
</span>55 <span style=''></span><span style='background: #AEF1AE'>      &quot; 'recall_at_target_precision' and 'cross_entropy_loss'.&quot;,
</span>56 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(
</span>57 <span style=''></span><span style='background: #AEF1AE'>      &quot;accuracy&quot;, &quot;f1&quot;, &quot;precision_at_target_recall&quot;,
</span>58 <span style=''></span><span style='background: #AEF1AE'>      &quot;recall_at_target_precision&quot;, &quot;cross_entropy_loss&quot;))
</span>59 <span style=''></span><span style='background: #AEF1AE'>  )</span><span style=''>
</span>60 <span style=''>  def getBinaryClassifierModelSelectionCriteria: String = </span><span style='background: #AEF1AE'>$(binaryClassifierModelSelectionCriteria)</span><span style=''>
</span>61 <span style=''>
</span>62 <span style=''>  /**
</span>63 <span style=''>    * Applicable if binary_classifier_model_selection_criteria is precision_at_target_recall
</span>64 <span style=''>    * Ignored otherwise. Must be in range (0, 1).
</span>65 <span style=''>    * Default: 0.8.
</span>66 <span style=''>    */
</span>67 <span style=''>  val targetRecall : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;target_recall&quot;,
</span>68 <span style=''></span><span style='background: #AEF1AE'>    &quot;Applicable if binary_classifier_model_selection_criteria is precision_at_target_recall. &quot; +
</span>69 <span style=''></span><span style='background: #AEF1AE'>      &quot;Ignored otherwise. Must be in range (0, 1).&quot;,
</span>70 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inRange(0.0, 1.0, false, false))</span><span style=''>
</span>71 <span style=''>  def getTargetRecall: Double = </span><span style='background: #AEF1AE'>$(targetRecall)</span><span style=''>
</span>72 <span style=''>
</span>73 <span style=''>  /**
</span>74 <span style=''>    * Applicable if binary_classifier_model_selection_criteria is recall_at_target_precision
</span>75 <span style=''>    * Ignored otherwise. Must be in range (0, 1).
</span>76 <span style=''>    * Default: 0.8.
</span>77 <span style=''>    */
</span>78 <span style=''>  val targetPrecision : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;target_precision&quot;,
</span>79 <span style=''></span><span style='background: #AEF1AE'>    &quot;Applicable if binary_classifier_model_selection_criteria is recall_at_target_precision. &quot; +
</span>80 <span style=''></span><span style='background: #AEF1AE'>      &quot;Ignored otherwise. Must be in range (0, 1).&quot;,
</span>81 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inRange(0.0, 1.0, false, false))</span><span style=''>
</span>82 <span style=''>  def getTargetPrecision: Double = </span><span style='background: #AEF1AE'>$(targetPrecision)</span><span style=''>
</span>83 <span style=''>}
</span>84 <span style=''>
</span>85 <span style=''>
</span>86 <span style=''>private[algorithms] trait LinearLearnerParams extends SageMakerAlgorithmParams {
</span>87 <span style=''>
</span>88 <span style=''>  /**
</span>89 <span style=''>    * Max number of passes over the data. Must be &gt; 0.
</span>90 <span style=''>    * Default: 10.
</span>91 <span style=''>    */
</span>92 <span style=''>  val epochs : IntParam = </span><span style='background: #AEF1AE'>new IntParam(this, &quot;epochs&quot;,
</span>93 <span style=''></span><span style='background: #AEF1AE'>    &quot;Max number of passes over the data. Must be &gt; 0.&quot;,
</span>94 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.gt(0))</span><span style=''>
</span>95 <span style=''>  def getEpochs: Int = </span><span style='background: #AEF1AE'>$(epochs)</span><span style=''>
</span>96 <span style=''>
</span>97 <span style=''>  /**
</span>98 <span style=''>    * Whether training is for binary classification or regression.
</span>99 <span style=''>    * Supported options: &quot;binary_classifier&quot;, and &quot;regressor&quot;.
</span>100 <span style=''>    * Required
</span>101 <span style=''>    */
</span>102 <span style=''>  private[algorithms] val predictorType : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;predictor_type&quot;,
</span>103 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether training is for binary classification or regression. &quot; +
</span>104 <span style=''></span><span style='background: #AEF1AE'>    &quot;Supported options: 'binary_classifier', and 'regressor'.&quot;,
</span>105 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;binary_classifier&quot;, &quot;regressor&quot;)))</span><span style=''>
</span>106 <span style=''>
</span>107 <span style=''>  /**
</span>108 <span style=''>    * Whether model should include bias.
</span>109 <span style=''>    * Default: &quot;True&quot;.
</span>110 <span style=''>    */
</span>111 <span style=''>  val useBias : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;use_bias&quot;,
</span>112 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether model should include bias. &quot;,
</span>113 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;True&quot;, &quot;False&quot;)))</span><span style=''>
</span>114 <span style=''>  def getUseBias: Boolean = </span><span style='background: #AEF1AE'>parseTrueAndFalse(useBias)</span><span style=''>
</span>115 <span style=''>
</span>116 <span style=''>  /**
</span>117 <span style=''>    * Number of models to train in parallel. Must be &gt; 0 or &quot;auto&quot;.
</span>118 <span style=''>    * If default &quot;auto&quot; is selected, the number of parallel models to train will be decided by
</span>119 <span style=''>    * the algorithm itself.
</span>120 <span style=''>    * Default: &quot;auto&quot;.
</span>121 <span style=''>    */
</span>122 <span style=''>  val numModels : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;num_models&quot;,
</span>123 <span style=''></span><span style='background: #AEF1AE'>    &quot;Number of models to train in parallel. Must be &gt; 0 or 'auto'&quot;,
</span>124 <span style=''></span><span style='background: #AEF1AE'>    autoOrAboveParamValidator(0, false))</span><span style=''>
</span>125 <span style=''>  def getNumModels: String = </span><span style='background: #AEF1AE'>$(numModels)</span><span style=''>
</span>126 <span style=''>
</span>127 <span style=''>  /**
</span>128 <span style=''>    * Number of samples to use from validation dataset for doing model calibration
</span>129 <span style=''>    * (finding the best threshold). Must be &gt; 0.
</span>130 <span style=''>    * Default: 10000000.
</span>131 <span style=''>    */
</span>132 <span style=''>  val numCalibrationSamples : IntParam = </span><span style='background: #AEF1AE'>new IntParam(this, &quot;num_calibration_samples&quot;,
</span>133 <span style=''></span><span style='background: #AEF1AE'>    &quot;Number of samples to use from validation dataset for doing model calibration&quot; +
</span>134 <span style=''></span><span style='background: #AEF1AE'>      &quot; (finding the best threshold). Must be &gt; 0.&quot;,
</span>135 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.gt(0))</span><span style=''>
</span>136 <span style=''>  def getNumCalibrationSamples: Int = </span><span style='background: #AEF1AE'>$(numCalibrationSamples)</span><span style=''>
</span>137 <span style=''>
</span>138 <span style=''>  /**
</span>139 <span style=''>    * Initialization function for the model weights. Supported options: &quot;uniform&quot; and &quot;normal&quot;.
</span>140 <span style=''>    * uniform: uniformly between (-scale, +scale)
</span>141 <span style=''>    * normal: normal with mean 0 and sigma
</span>142 <span style=''>    * Default: &quot;uniform&quot;.
</span>143 <span style=''>    */
</span>144 <span style=''>  val initMethod : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;init_method&quot;,
</span>145 <span style=''></span><span style='background: #AEF1AE'>    &quot;Initialization function for the model weights. Supported options: 'uniform' and 'normal'.&quot;,
</span>146 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;uniform&quot;, &quot;normal&quot;)))</span><span style=''>
</span>147 <span style=''>  def getInitMethod: String = </span><span style='background: #AEF1AE'>$(initMethod)</span><span style=''>
</span>148 <span style=''>
</span>149 <span style=''>  /**
</span>150 <span style=''>    * Scale for init method uniform. Must be &gt; 0.
</span>151 <span style=''>    * Default: 0.07.
</span>152 <span style=''>    */
</span>153 <span style=''>  val initScale : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;init_scale&quot;,
</span>154 <span style=''></span><span style='background: #AEF1AE'>    &quot;Scale for init method uniform. Must be &gt; 0.&quot;,
</span>155 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.gt(0))</span><span style=''>
</span>156 <span style=''>  def getInitScale: Double = </span><span style='background: #AEF1AE'>$(initScale)</span><span style=''>
</span>157 <span style=''>
</span>158 <span style=''>  /**
</span>159 <span style=''>    * Standard deviation for init method normal. Must be &gt; 0.
</span>160 <span style=''>    * Default: 0.01.
</span>161 <span style=''>    */
</span>162 <span style=''>  val initSigma : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;init_sigma&quot;,
</span>163 <span style=''></span><span style='background: #AEF1AE'>    &quot;Standard deviation for init method normal. Must be &gt; 0.&quot;,
</span>164 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.gt(0))</span><span style=''>
</span>165 <span style=''>  def getInitSigma: Double = </span><span style='background: #AEF1AE'>$(initSigma)</span><span style=''>
</span>166 <span style=''>
</span>167 <span style=''>  /**
</span>168 <span style=''>    * Initial weight for bias.
</span>169 <span style=''>    * Default: 0.
</span>170 <span style=''>    */
</span>171 <span style=''>  val initBias : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;init_bias&quot;,
</span>172 <span style=''></span><span style='background: #AEF1AE'>    &quot;Initial weight for bias. &quot; + &quot;Must be number.&quot;)</span><span style=''>
</span>173 <span style=''>  def getInitBias: Double = </span><span style='background: #AEF1AE'>$(initBias)</span><span style=''>
</span>174 <span style=''>
</span>175 <span style=''>  /**
</span>176 <span style=''>    * Which optimizer is to be used. Supported options: &quot;sgd&quot; and &quot;adam&quot;.
</span>177 <span style=''>    * Default: &quot;adam&quot;.
</span>178 <span style=''>    */
</span>179 <span style=''>  val optimizer : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;optimizer&quot;, &quot;Which optimizer is to be used. &quot; +
</span>180 <span style=''></span><span style='background: #AEF1AE'>    &quot;Supported options: 'sgd' and 'adam'.&quot;,
</span>181 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;sgd&quot;, &quot;adam&quot;)))</span><span style=''>
</span>182 <span style=''>  def getOptimizer: String = </span><span style='background: #AEF1AE'>$(optimizer)</span><span style=''>
</span>183 <span style=''>
</span>184 <span style=''>  /**
</span>185 <span style=''>    * The loss function to apply. Supported options: &quot;logistic&quot;, &quot;squared_loss&quot; and &quot;auto&quot;.
</span>186 <span style=''>    * Default: &quot;auto&quot;.
</span>187 <span style=''>    */
</span>188 <span style=''>  val loss : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;loss&quot;, &quot;The loss function to apply. &quot; +
</span>189 <span style=''></span><span style='background: #AEF1AE'>    &quot;Supported options: 'logistic', 'squared_loss' and 'auto'.&quot;,
</span>190 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;logistic&quot;, &quot;squared_loss&quot;, &quot;auto&quot;)))</span><span style=''>
</span>191 <span style=''>  def getLoss: String = </span><span style='background: #AEF1AE'>$(loss)</span><span style=''>
</span>192 <span style=''>
</span>193 <span style=''>  /**
</span>194 <span style=''>    * The L2 regularization, i.e. the weight decay parameter. Use 0 for no L2 regularization.
</span>195 <span style=''>    * Must be &gt;= 0.
</span>196 <span style=''>    * Default: 0.
</span>197 <span style=''>    */
</span>198 <span style=''>  val wd : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;wd&quot;,
</span>199 <span style=''></span><span style='background: #AEF1AE'>    &quot;The L2 regularization, i.e. the weight decay parameter. Must be &gt;= 0.&quot;,
</span>200 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.gtEq(0))</span><span style=''>
</span>201 <span style=''>  def getWd: Double = </span><span style='background: #AEF1AE'>$(wd)</span><span style=''>
</span>202 <span style=''>
</span>203 <span style=''>  /**
</span>204 <span style=''>    * The L1 regularization parameter. Use 0 for no L1 regularization. Must be &gt;= 0.
</span>205 <span style=''>    * Default: 0.
</span>206 <span style=''>    */
</span>207 <span style=''>  val l1 : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;l1&quot;,
</span>208 <span style=''></span><span style='background: #AEF1AE'>    &quot;The L1 regularization parameter. Use 0 for no L1 regularization. Must be &gt;= 0.&quot;,
</span>209 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.gtEq(0))</span><span style=''>
</span>210 <span style=''>  def getL1: Double = </span><span style='background: #AEF1AE'>$(l1)</span><span style=''>
</span>211 <span style=''>
</span>212 <span style=''>  /**
</span>213 <span style=''>    * Momentum parameter of sgd optimizer. Must be in range [0, 1).
</span>214 <span style=''>    * Default: 0.
</span>215 <span style=''>    */
</span>216 <span style=''>  val momentum : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;momentum&quot;,
</span>217 <span style=''></span><span style='background: #AEF1AE'>    &quot;Momentum parameter of sgd optimizer. Must be in range [0, 1).&quot;,
</span>218 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inRange(0.0, 1.0, true, false))</span><span style=''>
</span>219 <span style=''>  def getMomentum: Double = </span><span style='background: #AEF1AE'>$(momentum)</span><span style=''>
</span>220 <span style=''>
</span>221 <span style=''>  /**
</span>222 <span style=''>    * The learning rate. Must be &gt; 0 or &quot;auto&quot;.
</span>223 <span style=''>    * Default: &quot;auto&quot;.
</span>224 <span style=''>    */
</span>225 <span style=''>  val learningRate : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;learning_rate&quot;,
</span>226 <span style=''></span><span style='background: #AEF1AE'>    &quot;The learning rate. Must be &gt; 0 or 'auto'&quot;,
</span>227 <span style=''></span><span style='background: #AEF1AE'>    autoOrAboveParamValidator(0, false))</span><span style=''>
</span>228 <span style=''>  def getLearningRate: String = </span><span style='background: #AEF1AE'>$(learningRate)</span><span style=''>
</span>229 <span style=''>
</span>230 <span style=''>  /**
</span>231 <span style=''>    * Parameter specific to adam optimizer. Exponential decay rate for first moment estimates.
</span>232 <span style=''>    * Ignored when optimizer is not adam. Must be in range [0, 1).
</span>233 <span style=''>    * Default: 0.9.
</span>234 <span style=''>    */
</span>235 <span style=''>  val beta1 : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;beta_1&quot;,
</span>236 <span style=''></span><span style='background: #AEF1AE'>    &quot;Parameter specific to adam optimizer. Exponential decay rate for first moment estimates. &quot; +
</span>237 <span style=''></span><span style='background: #AEF1AE'>      &quot;Ignored when optimizer is not adam. Must be in range [0, 1).&quot;,
</span>238 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inRange(0.0, 1.0, true, false))</span><span style=''>
</span>239 <span style=''>  def getBeta1: Double = </span><span style='background: #AEF1AE'>$(beta1)</span><span style=''>
</span>240 <span style=''>
</span>241 <span style=''>  /**
</span>242 <span style=''>    * Parameter specific to adam optimizer. Exponential decay rate for second moment estimates.
</span>243 <span style=''>    * Ignored when optimizer is not adam. Must be in range [0, 1).
</span>244 <span style=''>    * Default: 0.999.
</span>245 <span style=''>    */
</span>246 <span style=''>  val beta2 : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;beta_2&quot;,
</span>247 <span style=''></span><span style='background: #AEF1AE'>    &quot;Parameter specific to adam optimizer. exponential decay rate for second moment estimates. &quot; +
</span>248 <span style=''></span><span style='background: #AEF1AE'>      &quot;Ignored when optimizer is not adam. Must be in range [0, 1).&quot;,
</span>249 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inRange(0.0, 1.0, true, false))</span><span style=''>
</span>250 <span style=''>  def getBeta2: Double = </span><span style='background: #AEF1AE'>$(beta2)</span><span style=''>
</span>251 <span style=''>
</span>252 <span style=''>  /**
</span>253 <span style=''>    * Learning rate bias multiplier.
</span>254 <span style=''>    * The actual learning rate for the bias is learning rate times bias_lr_mult. Must be &gt; 0.
</span>255 <span style=''>    * Default: 10.
</span>256 <span style=''>    */
</span>257 <span style=''>  val biasLrMult : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;bias_lr_mult&quot;,
</span>258 <span style=''></span><span style='background: #AEF1AE'>    &quot;Learning rate bias multiplier. &quot; +
</span>259 <span style=''></span><span style='background: #AEF1AE'>      &quot;The actual learning rate for the bias is learning rate times bias_lr_mult. &quot; +
</span>260 <span style=''></span><span style='background: #AEF1AE'>      &quot;Must be &gt; 0.&quot;, ParamValidators.gt(0))</span><span style=''>
</span>261 <span style=''>  def getBiasLrMult: Double = </span><span style='background: #AEF1AE'>$(biasLrMult)</span><span style=''>
</span>262 <span style=''>
</span>263 <span style=''>  /**
</span>264 <span style=''>    * Weight decay parameter multiplier.
</span>265 <span style=''>    * The actual L2 regularization weight for the bias is wd times bias_wd_mult. Must be &gt;= 0.
</span>266 <span style=''>    * Default: 0.
</span>267 <span style=''>    */
</span>268 <span style=''>  val biasWdMult : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;bias_wd_mult&quot;,
</span>269 <span style=''></span><span style='background: #AEF1AE'>    &quot;Weight decay parameter multiplier. &quot; +
</span>270 <span style=''></span><span style='background: #AEF1AE'>      &quot;The actual L2 regularization weight for the bias is wd times bias_wd_mult. &quot; +
</span>271 <span style=''></span><span style='background: #AEF1AE'>      &quot;Must be &gt;= 0.&quot;, ParamValidators.gtEq(0))</span><span style=''>
</span>272 <span style=''>  def getBiasWdMult: Double = </span><span style='background: #AEF1AE'>$(biasWdMult)</span><span style=''>
</span>273 <span style=''>
</span>274 <span style=''>  /**
</span>275 <span style=''>    * Whether to use a scheduler for the learning rate.
</span>276 <span style=''>    * Default: True
</span>277 <span style=''>    */
</span>278 <span style=''>  val useLrScheduler : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;use_lr_scheduler&quot;,
</span>279 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether to use a scheduler for the learning rate. &quot;,
</span>280 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;True&quot;, &quot;False&quot;)))</span><span style=''>
</span>281 <span style=''>  def getUseLrScheduler: Boolean = </span><span style='background: #AEF1AE'>parseTrueAndFalse(useLrScheduler)</span><span style=''>
</span>282 <span style=''>
</span>283 <span style=''>  /**
</span>284 <span style=''>    * Parameter specific to lr_scheduler. Ignored otherwise.
</span>285 <span style=''>    * The number of steps between decreases of the learning rate. Must be &gt; 0.
</span>286 <span style=''>    * Default: 100.
</span>287 <span style=''>    */
</span>288 <span style=''>  val lrSchedulerStep : IntParam = </span><span style='background: #AEF1AE'>new IntParam(this, &quot;lr_scheduler_step&quot;,
</span>289 <span style=''></span><span style='background: #AEF1AE'>    &quot;Parameter specific to lr_scheduler. Ignored otherwise.&quot; +
</span>290 <span style=''></span><span style='background: #AEF1AE'>      &quot;The number of steps between decreases of the learning rate. &quot; +
</span>291 <span style=''></span><span style='background: #AEF1AE'>      &quot;Must be &gt; 0.&quot;, ParamValidators.gt(0))</span><span style=''>
</span>292 <span style=''>  def getLrSchedulerStep: Int = </span><span style='background: #AEF1AE'>$(lrSchedulerStep)</span><span style=''>
</span>293 <span style=''>
</span>294 <span style=''>  /**
</span>295 <span style=''>    * Parameter specific to lr_scheduler. Ignored otherwise.
</span>296 <span style=''>    * Every lr_scheduler_step the learning rate will decrease by this quantity. Must be in (0, 1).
</span>297 <span style=''>    * Default: 0.99.
</span>298 <span style=''>    */
</span>299 <span style=''>  val lrSchedulerFactor : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;lr_scheduler_factor&quot;,
</span>300 <span style=''></span><span style='background: #AEF1AE'>    &quot;Parameter specific to lr_scheduler. Ignored otherwise.&quot; +
</span>301 <span style=''></span><span style='background: #AEF1AE'>      &quot;Every lr_scheduler_step the learning rate will decrease by this quantity. &quot; +
</span>302 <span style=''></span><span style='background: #AEF1AE'>      &quot;Must be in (0, 1).&quot;, ParamValidators.inRange(0, 1, false, false))</span><span style=''>
</span>303 <span style=''>  def getLrSchedulerFactor: Double = </span><span style='background: #AEF1AE'>$(lrSchedulerFactor)</span><span style=''>
</span>304 <span style=''>
</span>305 <span style=''>  /**
</span>306 <span style=''>    * Parameter specific to lr_scheduler. Ignored otherwise.
</span>307 <span style=''>    * The learning rate will never decrease to a value lower than lr_scheduler_minimum_lr.
</span>308 <span style=''>    * Must be &gt; 0.
</span>309 <span style=''>    * Default: 1e-5.
</span>310 <span style=''>    */
</span>311 <span style=''>  val lrSchedulerMinimumLr : DoubleParam = </span><span style='background: #AEF1AE'>new DoubleParam(this, &quot;lr_scheduler_minimum_lr&quot;,
</span>312 <span style=''></span><span style='background: #AEF1AE'>    &quot;Parameter specific to lr_scheduler. Ignored otherwise.&quot; +
</span>313 <span style=''></span><span style='background: #AEF1AE'>      &quot;The learning rate will never decrease to a value lower than lr_scheduler_minimum_lr. &quot; +
</span>314 <span style=''></span><span style='background: #AEF1AE'>      &quot;Must be &gt; 0.&quot;, ParamValidators.gt(0))</span><span style=''>
</span>315 <span style=''>  def getLrSchedulerMinimumLr: Double = </span><span style='background: #AEF1AE'>$(lrSchedulerMinimumLr)</span><span style=''>
</span>316 <span style=''>
</span>317 <span style=''>  /**
</span>318 <span style=''>    * Whether to normalize the features before training to have std_dev of 1.
</span>319 <span style=''>    * Default: True
</span>320 <span style=''>    */
</span>321 <span style=''>  val normalizeData : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;normalize_data&quot;,
</span>322 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether to normalize the features before training to have std_dev of 1. &quot;,
</span>323 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;True&quot;, &quot;False&quot;)))</span><span style=''>
</span>324 <span style=''>  def getNormalizeData: Boolean = </span><span style='background: #AEF1AE'>parseTrueAndFalse(normalizeData)</span><span style=''>
</span>325 <span style=''>
</span>326 <span style=''>  /**
</span>327 <span style=''>    * Whether regression label is normalized. Ignored in classification.
</span>328 <span style=''>    * Default: &quot;auto&quot;
</span>329 <span style=''>    */
</span>330 <span style=''>  val normalizeLabel : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;normalize_label&quot;,
</span>331 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether regression label is normalized. If set for classification, it will be ignored.&quot;,
</span>332 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;True&quot;, &quot;False&quot;)))</span><span style=''>
</span>333 <span style=''>  def getNormalizeLabel: Boolean = </span><span style='background: #AEF1AE'>parseTrueAndFalse(normalizeLabel)</span><span style=''>
</span>334 <span style=''>
</span>335 <span style=''>  /**
</span>336 <span style=''>    * Whether to unbias the features before training so that mean is 0.
</span>337 <span style=''>    * By default data is unbiased if use_bias is set to true.
</span>338 <span style=''>    * Default: &quot;auto&quot;
</span>339 <span style=''>    */
</span>340 <span style=''>  val unbiasData : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;unbias_data&quot;,
</span>341 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether to unbias the features before training so that mean is 0. &quot; +
</span>342 <span style=''></span><span style='background: #AEF1AE'>      &quot;By default data is unbiased if use_bias is set to true.&quot;,
</span>343 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;True&quot;, &quot;False&quot;)))</span><span style=''>
</span>344 <span style=''>  def getUnbiasData: Boolean = </span><span style='background: #AEF1AE'>parseTrueAndFalse(unbiasData)</span><span style=''>
</span>345 <span style=''>
</span>346 <span style=''>  /**
</span>347 <span style=''>    * Whether to unbias the labels before training so that mean is 0.
</span>348 <span style=''>    * Only done for regrssion if use_bias is true. Otherwise will be ignored.
</span>349 <span style=''>    * Default: &quot;auto&quot;
</span>350 <span style=''>    */
</span>351 <span style=''>  val unbiasLabel : Param[String] = </span><span style='background: #AEF1AE'>new Param(this, &quot;unbias_label&quot;,
</span>352 <span style=''></span><span style='background: #AEF1AE'>    &quot;Whether to unbias the labels before training so that mean is 0. &quot; +
</span>353 <span style=''></span><span style='background: #AEF1AE'>      &quot;Only done for regrssion if use_bias is true. Otherwise will be ignored.&quot;,
</span>354 <span style=''></span><span style='background: #AEF1AE'>    ParamValidators.inArray(Array(&quot;True&quot;, &quot;False&quot;)))</span><span style=''>
</span>355 <span style=''>  def getUnbiasLabel: Boolean = </span><span style='background: #AEF1AE'>parseTrueAndFalse(unbiasLabel)</span><span style=''>
</span>356 <span style=''>
</span>357 <span style=''>  /**
</span>358 <span style=''>    * Number of data points to use for calcuating the normalizing / unbiasing terms. Must be &gt; 0.
</span>359 <span style=''>    * Default: 10000.
</span>360 <span style=''>    */
</span>361 <span style=''>  val numPointForScaler : IntParam = </span><span style='background: #AEF1AE'>new IntParam(this, &quot;num_point_for_scaler&quot;,
</span>362 <span style=''></span><span style='background: #AEF1AE'>    &quot;Number of data points to use for calcuating the normalizing / unbiasing terms. &quot; +
</span>363 <span style=''></span><span style='background: #AEF1AE'>      &quot;Must be &gt; 0.&quot;, ParamValidators.gt(0))</span><span style=''>
</span>364 <span style=''>  def getNumPointForScaler: Int = </span><span style='background: #AEF1AE'>$(numPointForScaler)</span><span style=''>
</span>365 <span style=''>}
</span>366 <span style=''>
</span>367 <span style=''>object LinearLearnerSageMakerEstimator {
</span>368 <span style=''>  val algorithmName = </span><span style='background: #AEF1AE'>&quot;linear-learner&quot;</span><span style=''>
</span>369 <span style=''>  val algorithmTag = </span><span style='background: #AEF1AE'>&quot;1&quot;</span><span style=''>
</span>370 <span style=''>  val regionAccountMap = </span><span style='background: #AEF1AE'>SagerMakerRegionAccountMaps.AlgorithmsAccountMap</span><span style=''>
</span>371 <span style=''>}
</span>372 <span style=''>
</span>373 <span style=''>/**
</span>374 <span style=''>  * A [[SageMakerEstimator]] that runs a Linear Learner training job in &quot;binary classifier&quot; mode
</span>375 <span style=''>  * in SageMaker and returns a [[SageMakerModel]] that can be used to transform a DataFrame using
</span>376 <span style=''>  * the hosted Linear Learner model. The Linear Learner Binary Classifier is useful for classifying
</span>377 <span style=''>  * examples into one of two classes.
</span>378 <span style=''>  *
</span>379 <span style=''>  * Amazon SageMaker Linear Learner trains on RecordIO-encoded Amazon Record protobuf data.
</span>380 <span style=''>  * SageMaker Spark writes a DataFrame to S3 by selecting a column of Vectors named &quot;features&quot;
</span>381 <span style=''>  * and, if present, a column of Doubles named &quot;label&quot;. These names are configurable by passing
</span>382 <span style=''>  * a map with entries in trainingSparkDataFormatOptions with key &quot;labelColumnName&quot; or
</span>383 <span style=''>  * &quot;featuresColumnName&quot;, with values corresponding to the desired label and features columns.
</span>384 <span style=''>  *
</span>385 <span style=''>  * Inferences made against an Endpoint hosting a Linear Learner Binary classifier model contain
</span>386 <span style=''>  * a &quot;score&quot; field and a &quot;predicted_label&quot; field, both appended to the input DataFrame as
</span>387 <span style=''>  * Doubles.
</span>388 <span style=''>  *
</span>389 <span style=''>  * @param sagemakerRole The SageMaker TrainingJob and Hosting IAM Role. Used by a SageMaker to
</span>390 <span style=''>  *                      access S3 and ECR resources. SageMaker hosted Endpoints instances
</span>391 <span style=''>  *                      launched by this Estimator run with this role.
</span>392 <span style=''>  * @param trainingInstanceType The SageMaker TrainingJob Instance Type to use
</span>393 <span style=''>  * @param trainingInstanceCount The number of instances of instanceType to run an
</span>394 <span style=''>  *                              SageMaker Training Job with
</span>395 <span style=''>  * @param endpointInstanceType The SageMaker Endpoint Confing instance type
</span>396 <span style=''>  * @param endpointInitialInstanceCount The SageMaker Endpoint Config minimum number of instances
</span>397 <span style=''>  *                                     that can be used to host modelImage
</span>398 <span style=''>  * @param requestRowSerializer Serializes Spark DataFrame [[Row]]s for transformation by Models
</span>399 <span style=''>  *                             built from this Estimator.
</span>400 <span style=''>  * @param responseRowDeserializer Deserializes an Endpoint response into a series of [[Row]]s.
</span>401 <span style=''>  * @param trainingInputS3DataPath An S3 location to upload SageMaker Training Job input data to.
</span>402 <span style=''>  * @param trainingOutputS3DataPath An S3 location for SageMaker to store Training Job output
</span>403 <span style=''>  *                                 data to.
</span>404 <span style=''>  * @param trainingInstanceVolumeSizeInGB The EBS volume size in gigabytes of each instance.
</span>405 <span style=''>  * @param trainingProjectedColumns The columns to project from the Dataset being fit before
</span>406 <span style=''>  *                                 training. If an Optional.empty is passed then no specific
</span>407 <span style=''>  *                                 projection will occur and all columns will be serialized.
</span>408 <span style=''>  * @param trainingChannelName The SageMaker Channel name to input serialized Dataset fit input to
</span>409 <span style=''>  * @param trainingContentType The MIME type of the training data.
</span>410 <span style=''>  * @param trainingS3DataDistribution The SageMaker Training Job S3 data distribution scheme.
</span>411 <span style=''>  * @param trainingSparkDataFormat The Spark Data Format name used to serialize the Dataset being
</span>412 <span style=''>  *                                fit for input to SageMaker.
</span>413 <span style=''>  * @param trainingSparkDataFormatOptions The Spark Data Format Options used during serialization of
</span>414 <span style=''>  *                                       the Dataset being fit.
</span>415 <span style=''>  * @param trainingInputMode The SageMaker Training Job Channel input mode.
</span>416 <span style=''>  * @param trainingCompressionCodec The type of compression to use when serializing the Dataset
</span>417 <span style=''>  *                                 being fit for input to SageMaker.
</span>418 <span style=''>  * @param trainingMaxRuntimeInSeconds A SageMaker Training Job Termination Condition
</span>419 <span style=''>  *                                    MaxRuntimeInHours.
</span>420 <span style=''>  * @param trainingKmsKeyId A KMS key ID for the Output Data Source
</span>421 <span style=''>  * @param modelEnvironmentVariables The environment variables that SageMaker will set on the model
</span>422 <span style=''>  *                                  container during execution.
</span>423 <span style=''>  * @param endpointCreationPolicy Defines how a SageMaker Endpoint referenced by a
</span>424 <span style=''>  *                               SageMakerModel is created.
</span>425 <span style=''>  * @param sagemakerClient Amazon SageMaker client. Used to send CreateTrainingJob, CreateModel,
</span>426 <span style=''>  *                        and CreateEndpoint requests.
</span>427 <span style=''>  * @param region The region in which to run the algorithm. If not specified, gets the region from
</span>428 <span style=''>  *               the DefaultAwsRegionProviderChain.
</span>429 <span style=''>  * @param s3Client AmazonS3. Used to create a bucket for staging SageMaker Training Job input
</span>430 <span style=''>  *                 and/or output if either are set to S3AutoCreatePath.
</span>431 <span style=''>  * @param stsClient AmazonSTS. Used to resolve the account number when creating staging
</span>432 <span style=''>  *                  input / output buckets.
</span>433 <span style=''>  * @param modelPrependInputRowsToTransformationRows Whether the transformation result on Models
</span>434 <span style=''>  *        built by this Estimator should also include the input Rows. If true, each output Row
</span>435 <span style=''>  *        is formed by a concatenation of the input Row with the corresponding Row produced by
</span>436 <span style=''>  *        SageMaker Endpoint invocation, produced by responseRowDeserializer.
</span>437 <span style=''>  *        If false, each output Row is just taken from responseRowDeserializer.
</span>438 <span style=''>  * @param deleteStagingDataAfterTraining Whether to remove the training data on s3 after training
</span>439 <span style=''>  *                                       is complete or failed.
</span>440 <span style=''>  * @param namePolicyFactory The [[NamePolicyFactory]] to use when naming SageMaker entities
</span>441 <span style=''>  *        created during fit
</span>442 <span style=''>  * @param uid The unique identifier of this Estimator. Used to represent this stage in Spark
</span>443 <span style=''>  *            ML pipelines.
</span>444 <span style=''>  */
</span>445 <span style=''>class LinearLearnerBinaryClassifier(
</span>446 <span style=''>           override val sagemakerRole : IAMRoleResource = IAMRoleFromConfig(),
</span>447 <span style=''>           override val trainingInstanceType : String,
</span>448 <span style=''>           override val trainingInstanceCount : Int,
</span>449 <span style=''>           override val endpointInstanceType : String,
</span>450 <span style=''>           override val endpointInitialInstanceCount : Int,
</span>451 <span style=''>           override val requestRowSerializer : RequestRowSerializer =
</span>452 <span style=''>           new ProtobufRequestRowSerializer(),
</span>453 <span style=''>           override val responseRowDeserializer : ResponseRowDeserializer =
</span>454 <span style=''>           new LinearLearnerBinaryClassifierProtobufResponseRowDeserializer(),
</span>455 <span style=''>           override val trainingInputS3DataPath : S3Resource = S3AutoCreatePath(),
</span>456 <span style=''>           override val trainingOutputS3DataPath : S3Resource = S3AutoCreatePath(),
</span>457 <span style=''>           override val trainingInstanceVolumeSizeInGB : Int = 1024,
</span>458 <span style=''>           override val trainingProjectedColumns : Option[List[String]] = None,
</span>459 <span style=''>           override val trainingChannelName : String = &quot;train&quot;,
</span>460 <span style=''>           override val trainingContentType: Option[String] = None,
</span>461 <span style=''>           override val trainingS3DataDistribution : String =
</span>462 <span style=''>             S3DataDistribution.ShardedByS3Key.toString,
</span>463 <span style=''>           override val trainingSparkDataFormat : String = &quot;sagemaker&quot;,
</span>464 <span style=''>           override val trainingSparkDataFormatOptions : Map[String, String] = Map(),
</span>465 <span style=''>           override val trainingInputMode : String = TrainingInputMode.File.toString,
</span>466 <span style=''>           override val trainingCompressionCodec : Option[String] = None,
</span>467 <span style=''>           override val trainingMaxRuntimeInSeconds : Int = 24 * 60 * 60,
</span>468 <span style=''>           override val trainingKmsKeyId : Option[String] = None,
</span>469 <span style=''>           override val modelEnvironmentVariables : Map[String, String] = Map(),
</span>470 <span style=''>           override val endpointCreationPolicy : EndpointCreationPolicy =
</span>471 <span style=''>             EndpointCreationPolicy.CREATE_ON_CONSTRUCT,
</span>472 <span style=''>           override val sagemakerClient : AmazonSageMaker
</span>473 <span style=''>             = AmazonSageMakerClientBuilder.defaultClient,
</span>474 <span style=''>           override val region : Option[String] = None,
</span>475 <span style=''>           override val s3Client : AmazonS3 = AmazonS3ClientBuilder.defaultClient(),
</span>476 <span style=''>           override val stsClient : AWSSecurityTokenService =
</span>477 <span style=''>             AWSSecurityTokenServiceClientBuilder.defaultClient(),
</span>478 <span style=''>           override val modelPrependInputRowsToTransformationRows : Boolean = true,
</span>479 <span style=''>           override val deleteStagingDataAfterTraining : Boolean = true,
</span>480 <span style=''>           override val namePolicyFactory : NamePolicyFactory = new RandomNamePolicyFactory(),
</span>481 <span style=''>           override val uid : String = Identifiable.randomUID(&quot;sagemaker&quot;))
</span>482 <span style=''>  extends LinearLearnerSageMakerEstimator(
</span>483 <span style=''>    sagemakerRole,
</span>484 <span style=''>    trainingInstanceType,
</span>485 <span style=''>    trainingInstanceCount,
</span>486 <span style=''>    endpointInstanceType,
</span>487 <span style=''>    endpointInitialInstanceCount,
</span>488 <span style=''>    requestRowSerializer,
</span>489 <span style=''>    responseRowDeserializer,
</span>490 <span style=''>    trainingInputS3DataPath,
</span>491 <span style=''>    trainingOutputS3DataPath,
</span>492 <span style=''>    trainingInstanceVolumeSizeInGB,
</span>493 <span style=''>    trainingProjectedColumns,
</span>494 <span style=''>    trainingChannelName,
</span>495 <span style=''>    trainingContentType,
</span>496 <span style=''>    trainingS3DataDistribution,
</span>497 <span style=''>    trainingSparkDataFormat,
</span>498 <span style=''>    trainingSparkDataFormatOptions,
</span>499 <span style=''>    trainingInputMode,
</span>500 <span style=''>    trainingCompressionCodec,
</span>501 <span style=''>    trainingMaxRuntimeInSeconds,
</span>502 <span style=''>    trainingKmsKeyId,
</span>503 <span style=''>    modelEnvironmentVariables,
</span>504 <span style=''>    endpointCreationPolicy,
</span>505 <span style=''>    sagemakerClient,
</span>506 <span style=''>    region,
</span>507 <span style=''>    s3Client,
</span>508 <span style=''>    stsClient,
</span>509 <span style=''>    modelPrependInputRowsToTransformationRows,
</span>510 <span style=''>    deleteStagingDataAfterTraining,
</span>511 <span style=''>    namePolicyFactory,
</span>512 <span style=''>    uid) with BinaryClassifierParams {
</span>513 <span style=''>
</span>514 <span style=''>  </span><span style='background: #AEF1AE'>setDefault(predictorType -&gt; &quot;binary_classifier&quot;)</span><span style=''>
</span>515 <span style=''>
</span>516 <span style=''>  def setBinaryClassifierModelSelectionCriteria(value: String): this.type =
</span>517 <span style=''>    </span><span style='background: #AEF1AE'>set(binaryClassifierModelSelectionCriteria, value)</span><span style=''>
</span>518 <span style=''>
</span>519 <span style=''>  def setTargetRecall(value: Double): this.type = </span><span style='background: #AEF1AE'>set(targetRecall, value)</span><span style=''>
</span>520 <span style=''>
</span>521 <span style=''>  def setTargetPrecision(value: Double): this.type = </span><span style='background: #AEF1AE'>set(targetPrecision, value)</span><span style=''>
</span>522 <span style=''>}
</span>523 <span style=''>
</span>524 <span style=''>
</span>525 <span style=''>/**
</span>526 <span style=''>  * A [[SageMakerEstimator]] that runs a Linear Learner training job in &quot;regressor&quot; mode in
</span>527 <span style=''>  * SageMaker and returns a [[SageMakerModel]] that can be used to transform a DataFrame using
</span>528 <span style=''>  * the hosted Linear Learner model. The Linear Learner Regressor is useful for predicting
</span>529 <span style=''>  * a real-valued label from training examples.
</span>530 <span style=''>  *
</span>531 <span style=''>  * Amazon SageMaker Linear Learner trains on RecordIO-encoded Amazon Record protobuf data.
</span>532 <span style=''>  * SageMaker Spark writes a DataFrame to S3 by selecting a column of Vectors named &quot;features&quot;
</span>533 <span style=''>  * and, if present, a column of Doubles named &quot;label&quot;. These names are configurable by passing
</span>534 <span style=''>  * a map with entries in trainingSparkDataFormatOptions with key &quot;labelColumnName&quot; or
</span>535 <span style=''>  * &quot;featuresColumnName&quot;, with values corresponding to the desired label and features columns.
</span>536 <span style=''>  *
</span>537 <span style=''>  * For inference against a hosted Endpoint, the SageMakerModel returned by fit() by
</span>538 <span style=''>  * Linear Learner uses [[ProtobufRequestRowSerializer]] to serialize Rows into
</span>539 <span style=''>  * RecordIO-encoded Amazon Record protobuf messages, by default selecting
</span>540 <span style=''>  * the column named &quot;features&quot; expected to contain a Vector of Doubles.
</span>541 <span style=''>  *
</span>542 <span style=''>  * Inferences made against an Endpoint hosting a Linear Learner Regressor model contain
</span>543 <span style=''>  * a &quot;score&quot; field appended to the input DataFrame as a Double
</span>544 <span style=''>  *
</span>545 <span style=''>  * @param sagemakerRole The SageMaker TrainingJob and Hosting IAM Role. Used by a SageMaker to
</span>546 <span style=''>  *                      access S3 and ECR resources. SageMaker hosted Endpoints instances
</span>547 <span style=''>  *                      launched by this Estimator run with this role.
</span>548 <span style=''>  * @param trainingInstanceType The SageMaker TrainingJob Instance Type to use
</span>549 <span style=''>  * @param trainingInstanceCount The number of instances of instanceType to run an
</span>550 <span style=''>  *                              SageMaker Training Job with
</span>551 <span style=''>  * @param endpointInstanceType The SageMaker Endpoint Confing instance type
</span>552 <span style=''>  * @param endpointInitialInstanceCount The SageMaker Endpoint Config minimum number of instances
</span>553 <span style=''>  *                                     that can be used to host modelImage
</span>554 <span style=''>  * @param requestRowSerializer Serializes Spark DataFrame [[Row]]s for transformation by Models
</span>555 <span style=''>  *                             built from this Estimator.
</span>556 <span style=''>  * @param responseRowDeserializer Deserializes an Endpoint response into a series of [[Row]]s.
</span>557 <span style=''>  * @param trainingInputS3DataPath An S3 location to upload SageMaker Training Job input data to.
</span>558 <span style=''>  * @param trainingOutputS3DataPath An S3 location for SageMaker to store Training Job output
</span>559 <span style=''>  *                                 data to.
</span>560 <span style=''>  * @param trainingInstanceVolumeSizeInGB The EBS volume size in gigabytes of each instance.
</span>561 <span style=''>  * @param trainingProjectedColumns The columns to project from the Dataset being fit before
</span>562 <span style=''>  *                                 training. If an Optional.empty is passed then no specific
</span>563 <span style=''>  *                                 projection will occur and all columns will be serialized.
</span>564 <span style=''>  * @param trainingChannelName The SageMaker Channel name to input serialized Dataset fit input to
</span>565 <span style=''>  * @param trainingContentType The MIME type of the training data.
</span>566 <span style=''>  * @param trainingS3DataDistribution The SageMaker Training Job S3 data distribution scheme.
</span>567 <span style=''>  * @param trainingSparkDataFormat The Spark Data Format name used to serialize the Dataset being
</span>568 <span style=''>  *                                fit for input to SageMaker.
</span>569 <span style=''>  * @param trainingSparkDataFormatOptions The Spark Data Format Options used during serialization of
</span>570 <span style=''>  *                                       the Dataset being fit.
</span>571 <span style=''>  * @param trainingInputMode The SageMaker Training Job Channel input mode.
</span>572 <span style=''>  * @param trainingCompressionCodec The type of compression to use when serializing the Dataset
</span>573 <span style=''>  *                                 being fit for input to SageMaker.
</span>574 <span style=''>  * @param trainingMaxRuntimeInSeconds A SageMaker Training Job Termination Condition
</span>575 <span style=''>  *                                    MaxRuntimeInHours.
</span>576 <span style=''>  * @param trainingKmsKeyId A KMS key ID for the Output Data Source
</span>577 <span style=''>  * @param modelEnvironmentVariables The environment variables that SageMaker will set on the model
</span>578 <span style=''>  *                                  container during execution.
</span>579 <span style=''>  * @param endpointCreationPolicy Defines how a SageMaker Endpoint referenced by a
</span>580 <span style=''>  *                               SageMakerModel is created.
</span>581 <span style=''>  * @param sagemakerClient Amazon SageMaker client. Used to send CreateTrainingJob, CreateModel,
</span>582 <span style=''>  *                        and CreateEndpoint requests.
</span>583 <span style=''>  * @param region The region in which to run the algorithm. If not specified, gets the region from
</span>584 <span style=''>  *               the DefaultAwsRegionProviderChain.
</span>585 <span style=''>  * @param s3Client AmazonS3. Used to create a bucket for staging SageMaker Training Job input
</span>586 <span style=''>  *                 and/or output if either are set to S3AutoCreatePath.
</span>587 <span style=''>  * @param stsClient AmazonSTS. Used to resolve the account number when creating staging
</span>588 <span style=''>  *                  input / output buckets.
</span>589 <span style=''>  * @param modelPrependInputRowsToTransformationRows Whether the transformation result on Models
</span>590 <span style=''>  *        built by this Estimator should also include the input Rows. If true, each output Row
</span>591 <span style=''>  *        is formed by a concatenation of the input Row with the corresponding Row produced by
</span>592 <span style=''>  *        SageMaker Endpoint invocation, produced by responseRowDeserializer.
</span>593 <span style=''>  *        If false, each output Row is just taken from responseRowDeserializer.
</span>594 <span style=''>  * @param deleteStagingDataAfterTraining Whether to remove the training data on s3 after training
</span>595 <span style=''>  *                                       is complete or failed.
</span>596 <span style=''>  * @param namePolicyFactory The [[NamePolicyFactory]] to use when naming SageMaker entities
</span>597 <span style=''>  *        created during fit
</span>598 <span style=''>  * @param uid The unique identifier of this Estimator. Used to represent this stage in Spark
</span>599 <span style=''>  *            ML pipelines.
</span>600 <span style=''>  */
</span>601 <span style=''>class LinearLearnerRegressor(
</span>602 <span style=''>                override val sagemakerRole : IAMRoleResource = IAMRoleFromConfig(),
</span>603 <span style=''>                override val trainingInstanceType : String,
</span>604 <span style=''>                override val trainingInstanceCount : Int,
</span>605 <span style=''>                override val endpointInstanceType : String,
</span>606 <span style=''>                override val endpointInitialInstanceCount : Int,
</span>607 <span style=''>                override val requestRowSerializer : RequestRowSerializer =
</span>608 <span style=''>                  new ProtobufRequestRowSerializer(),
</span>609 <span style=''>                override val responseRowDeserializer : ResponseRowDeserializer =
</span>610 <span style=''>                  new LinearLearnerRegressorProtobufResponseRowDeserializer(),
</span>611 <span style=''>                override val trainingInputS3DataPath : S3Resource = S3AutoCreatePath(),
</span>612 <span style=''>                override val trainingOutputS3DataPath : S3Resource = S3AutoCreatePath(),
</span>613 <span style=''>                override val trainingInstanceVolumeSizeInGB : Int = 1024,
</span>614 <span style=''>                override val trainingProjectedColumns : Option[List[String]] = None,
</span>615 <span style=''>                override val trainingChannelName : String = &quot;train&quot;,
</span>616 <span style=''>                override val trainingContentType: Option[String] = None,
</span>617 <span style=''>                override val trainingS3DataDistribution : String =
</span>618 <span style=''>                  S3DataDistribution.ShardedByS3Key.toString,
</span>619 <span style=''>                override val trainingSparkDataFormat : String = &quot;sagemaker&quot;,
</span>620 <span style=''>                override val trainingSparkDataFormatOptions : Map[String, String] = Map(),
</span>621 <span style=''>                override val trainingInputMode : String = TrainingInputMode.File.toString,
</span>622 <span style=''>                override val trainingCompressionCodec : Option[String] = None,
</span>623 <span style=''>                override val trainingMaxRuntimeInSeconds : Int = 24 * 60 * 60,
</span>624 <span style=''>                override val trainingKmsKeyId : Option[String] = None,
</span>625 <span style=''>                override val modelEnvironmentVariables : Map[String, String] = Map(),
</span>626 <span style=''>                override val endpointCreationPolicy : EndpointCreationPolicy =
</span>627 <span style=''>                  EndpointCreationPolicy.CREATE_ON_CONSTRUCT,
</span>628 <span style=''>                override val sagemakerClient : AmazonSageMaker
</span>629 <span style=''>                  = AmazonSageMakerClientBuilder.defaultClient,
</span>630 <span style=''>                override val region : Option[String] = None,
</span>631 <span style=''>                override val s3Client : AmazonS3 = AmazonS3ClientBuilder.defaultClient(),
</span>632 <span style=''>                override val stsClient : AWSSecurityTokenService =
</span>633 <span style=''>                  AWSSecurityTokenServiceClientBuilder.defaultClient(),
</span>634 <span style=''>                override val modelPrependInputRowsToTransformationRows : Boolean = true,
</span>635 <span style=''>                override val deleteStagingDataAfterTraining : Boolean = true,
</span>636 <span style=''>                override val namePolicyFactory : NamePolicyFactory
</span>637 <span style=''>                   = new RandomNamePolicyFactory(),
</span>638 <span style=''>                override val uid : String = Identifiable.randomUID(&quot;sagemaker&quot;))
</span>639 <span style=''>  extends LinearLearnerSageMakerEstimator(
</span>640 <span style=''>    sagemakerRole,
</span>641 <span style=''>    trainingInstanceType,
</span>642 <span style=''>    trainingInstanceCount,
</span>643 <span style=''>    endpointInstanceType,
</span>644 <span style=''>    endpointInitialInstanceCount,
</span>645 <span style=''>    requestRowSerializer,
</span>646 <span style=''>    responseRowDeserializer,
</span>647 <span style=''>    trainingInputS3DataPath,
</span>648 <span style=''>    trainingOutputS3DataPath,
</span>649 <span style=''>    trainingInstanceVolumeSizeInGB,
</span>650 <span style=''>    trainingProjectedColumns,
</span>651 <span style=''>    trainingChannelName,
</span>652 <span style=''>    trainingContentType,
</span>653 <span style=''>    trainingS3DataDistribution,
</span>654 <span style=''>    trainingSparkDataFormat,
</span>655 <span style=''>    trainingSparkDataFormatOptions,
</span>656 <span style=''>    trainingInputMode,
</span>657 <span style=''>    trainingCompressionCodec,
</span>658 <span style=''>    trainingMaxRuntimeInSeconds,
</span>659 <span style=''>    trainingKmsKeyId,
</span>660 <span style=''>    modelEnvironmentVariables,
</span>661 <span style=''>    endpointCreationPolicy,
</span>662 <span style=''>    sagemakerClient,
</span>663 <span style=''>    region,
</span>664 <span style=''>    s3Client,
</span>665 <span style=''>    stsClient,
</span>666 <span style=''>    modelPrependInputRowsToTransformationRows,
</span>667 <span style=''>    deleteStagingDataAfterTraining,
</span>668 <span style=''>    namePolicyFactory,
</span>669 <span style=''>    uid) with LinearLearnerParams {
</span>670 <span style=''>      </span><span style='background: #AEF1AE'>setDefault(predictorType -&gt; &quot;regressor&quot;)</span><span style=''>
</span>671 <span style=''>  }
</span>672 <span style=''>
</span>673 <span style=''>/**
</span>674 <span style=''>  * A [[SageMakerEstimator]] that runs a Linear Learner training job in SageMaker and returns
</span>675 <span style=''>  * a [[SageMakerModel]] that can be used to transform a DataFrame using
</span>676 <span style=''>  * the hosted Linear Learner model. This algorithm can be run in either as a Linear Regressor
</span>677 <span style=''>  * (see [[LinearLearnerRegressor]]) or as a Binary Classifier
</span>678 <span style=''>  * (see [[LinearLearnerBinaryClassifier]]).
</span>679 <span style=''>  *
</span>680 <span style=''>  * Amazon SageMaker Linear Learner trains on RecordIO-encoded Amazon Record protobuf data.
</span>681 <span style=''>  * SageMaker Spark writes a DataFrame to S3 by selecting a column of Vectors named &quot;features&quot;
</span>682 <span style=''>  * and, if present, a column of Doubles named &quot;label&quot;. These names are configurable by passing
</span>683 <span style=''>  * a map with entries in trainingSparkDataFormatOptions with key &quot;labelColumnName&quot; or
</span>684 <span style=''>  * &quot;featuresColumnName&quot;, with values corresponding to the desired label and features columns.
</span>685 <span style=''>  *
</span>686 <span style=''>  * For inference against a hosted Endpoint, the SageMakerModel returned by fit() by
</span>687 <span style=''>  * Linear Learner uses [[ProtobufRequestRowSerializer]] to serialize Rows into
</span>688 <span style=''>  * RecordIO-encoded Amazon Record protobuf messages, by default selecting
</span>689 <span style=''>  * the column named &quot;features&quot; expected to contain a Vector of Doubles.
</span>690 <span style=''>  *
</span>691 <span style=''>  * @param sagemakerRole The SageMaker TrainingJob and Hosting IAM Role. Used by a SageMaker to
</span>692 <span style=''>  *                      access S3 and ECR resources. SageMaker hosted Endpoints instances
</span>693 <span style=''>  *                      launched by this Estimator run with this role.
</span>694 <span style=''>  * @param trainingInstanceType The SageMaker TrainingJob Instance Type to use
</span>695 <span style=''>  * @param trainingInstanceCount The number of instances of instanceType to run an
</span>696 <span style=''>  *                              SageMaker Training Job with
</span>697 <span style=''>  * @param endpointInstanceType The SageMaker Endpoint Confing instance type
</span>698 <span style=''>  * @param endpointInitialInstanceCount The SageMaker Endpoint Config minimum number of instances
</span>699 <span style=''>  *                                     that can be used to host modelImage
</span>700 <span style=''>  * @param requestRowSerializer Serializes Spark DataFrame [[Row]]s for transformation by Models
</span>701 <span style=''>  *                             built from this Estimator.
</span>702 <span style=''>  * @param responseRowDeserializer Deserializes an Endpoint response into a series of [[Row]]s.
</span>703 <span style=''>  * @param trainingInputS3DataPath An S3 location to upload SageMaker Training Job input data to.
</span>704 <span style=''>  * @param trainingOutputS3DataPath An S3 location for SageMaker to store Training Job output
</span>705 <span style=''>  *                                 data to.
</span>706 <span style=''>  * @param trainingInstanceVolumeSizeInGB The EBS volume size in gigabytes of each instance.
</span>707 <span style=''>  * @param trainingProjectedColumns The columns to project from the Dataset being fit before
</span>708 <span style=''>  *                                 training. If an Optional.empty is passed then no specific
</span>709 <span style=''>  *                                 projection will occur and all columns will be serialized.
</span>710 <span style=''>  * @param trainingChannelName The SageMaker Channel name to input serialized Dataset fit input to
</span>711 <span style=''>  * @param trainingContentType The MIME type of the training data.
</span>712 <span style=''>  * @param trainingS3DataDistribution The SageMaker Training Job S3 data distribution scheme.
</span>713 <span style=''>  * @param trainingSparkDataFormat The Spark Data Format name used to serialize the Dataset being
</span>714 <span style=''>  *                                fit for input to SageMaker.
</span>715 <span style=''>  * @param trainingSparkDataFormatOptions The Spark Data Format Options used during serialization of
</span>716 <span style=''>  *                                       the Dataset being fit.
</span>717 <span style=''>  * @param trainingInputMode The SageMaker Training Job Channel input mode.
</span>718 <span style=''>  * @param trainingCompressionCodec The type of compression to use when serializing the Dataset
</span>719 <span style=''>  *                                 being fit for input to SageMaker.
</span>720 <span style=''>  * @param trainingMaxRuntimeInSeconds A SageMaker Training Job Termination Condition
</span>721 <span style=''>  *                                    MaxRuntimeInHours.
</span>722 <span style=''>  * @param trainingKmsKeyId A KMS key ID for the Output Data Source
</span>723 <span style=''>  * @param modelEnvironmentVariables The environment variables that SageMaker will set on the model
</span>724 <span style=''>  *                                  container during execution.
</span>725 <span style=''>  * @param endpointCreationPolicy Defines how a SageMaker Endpoint referenced by a
</span>726 <span style=''>  *                               SageMakerModel is created.
</span>727 <span style=''>  * @param sagemakerClient Amazon SageMaker client. Used to send CreateTrainingJob, CreateModel,
</span>728 <span style=''>  *                        and CreateEndpoint requests.
</span>729 <span style=''>  * @param region The region in which to run the algorithm. If not specified, gets the region from
</span>730 <span style=''>  *               the DefaultAwsRegionProviderChain.
</span>731 <span style=''>  * @param s3Client AmazonS3. Used to create a bucket for staging SageMaker Training Job input
</span>732 <span style=''>  *                 and/or output if either are set to S3AutoCreatePath.
</span>733 <span style=''>  * @param stsClient AmazonSTS. Used to resolve the account number when creating staging
</span>734 <span style=''>  *                  input / output buckets.
</span>735 <span style=''>  * @param modelPrependInputRowsToTransformationRows Whether the transformation result on Models
</span>736 <span style=''>  *        built by this Estimator should also include the input Rows. If true, each output Row
</span>737 <span style=''>  *        is formed by a concatenation of the input Row with the corresponding Row produced by
</span>738 <span style=''>  *        SageMaker Endpoint invocation, produced by responseRowDeserializer.
</span>739 <span style=''>  *        If false, each output Row is just taken from responseRowDeserializer.
</span>740 <span style=''>  * @param deleteStagingDataAfterTraining Whether to remove the training data on s3 after training
</span>741 <span style=''>  *                                       is complete or failed.
</span>742 <span style=''>  * @param namePolicyFactory The [[NamePolicyFactory]] to use when naming SageMaker entities
</span>743 <span style=''>  *        created during fit
</span>744 <span style=''>  * @param uid The unique identifier of this Estimator. Used to represent this stage in Spark
</span>745 <span style=''>  *            ML pipelines.
</span>746 <span style=''>  */
</span>747 <span style=''>private[algorithms] class LinearLearnerSageMakerEstimator(
</span>748 <span style=''>                        override val sagemakerRole : IAMRoleResource = IAMRoleFromConfig(),
</span>749 <span style=''>                        override val trainingInstanceType : String,
</span>750 <span style=''>                        override val trainingInstanceCount : Int,
</span>751 <span style=''>                        override val endpointInstanceType : String,
</span>752 <span style=''>                        override val endpointInitialInstanceCount : Int,
</span>753 <span style=''>                        override val requestRowSerializer : RequestRowSerializer,
</span>754 <span style=''>                        override val responseRowDeserializer : ResponseRowDeserializer,
</span>755 <span style=''>                        override val trainingInputS3DataPath : S3Resource = S3AutoCreatePath(),
</span>756 <span style=''>                        override val trainingOutputS3DataPath : S3Resource = S3AutoCreatePath(),
</span>757 <span style=''>                        override val trainingInstanceVolumeSizeInGB : Int = 1024,
</span>758 <span style=''>                        override val trainingProjectedColumns : Option[List[String]] = None,
</span>759 <span style=''>                        override val trainingChannelName : String = &quot;train&quot;,
</span>760 <span style=''>                        override val trainingContentType: Option[String] = None,
</span>761 <span style=''>                        override val trainingS3DataDistribution : String =
</span>762 <span style=''>                          S3DataDistribution.ShardedByS3Key.toString,
</span>763 <span style=''>                        override val trainingSparkDataFormat : String = &quot;sagemaker&quot;,
</span>764 <span style=''>                        override val trainingSparkDataFormatOptions : Map[String, String] = Map(),
</span>765 <span style=''>                        override val trainingInputMode : String = TrainingInputMode.File.toString,
</span>766 <span style=''>                        override val trainingCompressionCodec : Option[String] = None,
</span>767 <span style=''>                        override val trainingMaxRuntimeInSeconds : Int = 24 * 60 * 60,
</span>768 <span style=''>                        override val trainingKmsKeyId : Option[String] = None,
</span>769 <span style=''>                        override val modelEnvironmentVariables : Map[String, String] = Map(),
</span>770 <span style=''>                        override val endpointCreationPolicy : EndpointCreationPolicy =
</span>771 <span style=''>                          EndpointCreationPolicy.CREATE_ON_CONSTRUCT,
</span>772 <span style=''>                        override val sagemakerClient : AmazonSageMaker
</span>773 <span style=''>                          = AmazonSageMakerClientBuilder.defaultClient,
</span>774 <span style=''>                        val region : Option[String] = None,
</span>775 <span style=''>                        override val s3Client : AmazonS3 = AmazonS3ClientBuilder.defaultClient(),
</span>776 <span style=''>                        override val stsClient : AWSSecurityTokenService =
</span>777 <span style=''>                          AWSSecurityTokenServiceClientBuilder.defaultClient(),
</span>778 <span style=''>                        override val modelPrependInputRowsToTransformationRows : Boolean = true,
</span>779 <span style=''>                        override val deleteStagingDataAfterTraining : Boolean = true,
</span>780 <span style=''>                        override val namePolicyFactory : NamePolicyFactory
</span>781 <span style=''>                          = new RandomNamePolicyFactory(),
</span>782 <span style=''>                        override val uid : String = Identifiable.randomUID(&quot;sagemaker&quot;))
</span>783 <span style=''>  extends SageMakerEstimator(
</span>784 <span style=''>    trainingImage = SageMakerImageURIProvider.getImage(
</span>785 <span style=''>      region.getOrElse(new DefaultAwsRegionProviderChain().getRegion),
</span>786 <span style=''>      LinearLearnerSageMakerEstimator.regionAccountMap,
</span>787 <span style=''>      LinearLearnerSageMakerEstimator.algorithmName,
</span>788 <span style=''>      LinearLearnerSageMakerEstimator.algorithmTag),
</span>789 <span style=''>    modelImage = SageMakerImageURIProvider.getImage(
</span>790 <span style=''>      region.getOrElse(new DefaultAwsRegionProviderChain().getRegion),
</span>791 <span style=''>      LinearLearnerSageMakerEstimator.regionAccountMap,
</span>792 <span style=''>      LinearLearnerSageMakerEstimator.algorithmName,
</span>793 <span style=''>      LinearLearnerSageMakerEstimator.algorithmTag),
</span>794 <span style=''>    sagemakerRole,
</span>795 <span style=''>    trainingInstanceType,
</span>796 <span style=''>    trainingInstanceCount,
</span>797 <span style=''>    endpointInstanceType,
</span>798 <span style=''>    endpointInitialInstanceCount,
</span>799 <span style=''>    requestRowSerializer,
</span>800 <span style=''>    responseRowDeserializer,
</span>801 <span style=''>    trainingInputS3DataPath,
</span>802 <span style=''>    trainingOutputS3DataPath,
</span>803 <span style=''>    trainingInstanceVolumeSizeInGB,
</span>804 <span style=''>    trainingProjectedColumns,
</span>805 <span style=''>    trainingChannelName,
</span>806 <span style=''>    trainingContentType,
</span>807 <span style=''>    trainingS3DataDistribution,
</span>808 <span style=''>    trainingSparkDataFormat,
</span>809 <span style=''>    trainingSparkDataFormatOptions,
</span>810 <span style=''>    trainingInputMode,
</span>811 <span style=''>    trainingCompressionCodec,
</span>812 <span style=''>    trainingMaxRuntimeInSeconds,
</span>813 <span style=''>    trainingKmsKeyId,
</span>814 <span style=''>    modelEnvironmentVariables,
</span>815 <span style=''>    endpointCreationPolicy,
</span>816 <span style=''>    sagemakerClient,
</span>817 <span style=''>    s3Client,
</span>818 <span style=''>    stsClient,
</span>819 <span style=''>    modelPrependInputRowsToTransformationRows,
</span>820 <span style=''>    deleteStagingDataAfterTraining,
</span>821 <span style=''>    namePolicyFactory,
</span>822 <span style=''>    uid) with LinearLearnerParams {
</span>823 <span style=''>
</span>824 <span style=''>  </span><span style='background: #AEF1AE'>setDefault(miniBatchSize -&gt; 1000)</span><span style=''>
</span>825 <span style=''>
</span>826 <span style=''>  def setFeatureDim(value: Int): this.type = </span><span style='background: #AEF1AE'>set(featureDim, value)</span><span style=''>
</span>827 <span style=''>
</span>828 <span style=''>  def setMiniBatchSize(value: Int): this.type = </span><span style='background: #AEF1AE'>set(miniBatchSize, value)</span><span style=''>
</span>829 <span style=''>
</span>830 <span style=''>  def setEpochs(value: Int): this.type = </span><span style='background: #AEF1AE'>set(epochs, value)</span><span style=''>
</span>831 <span style=''>
</span>832 <span style=''>  def setUseBias(value: Boolean): this.type = </span><span style='background: #AEF1AE'>set(useBias, value match {
</span>833 <span style=''></span><span style='background: #AEF1AE'>    case true =&gt; &quot;True&quot;
</span>834 <span style=''></span><span style='background: #AEF1AE'>    case false =&gt; &quot;False&quot;
</span>835 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>836 <span style=''>
</span>837 <span style=''>  def setNumModels(value: Int): this.type = </span><span style='background: #AEF1AE'>set(numModels, value.toString)</span><span style=''>
</span>838 <span style=''>
</span>839 <span style=''>  def setNumModels(value: String): this.type = </span><span style='background: #AEF1AE'>set(numModels, value)</span><span style=''>
</span>840 <span style=''>
</span>841 <span style=''>  def setNumCalibrationSamples(value: Int): this.type = </span><span style='background: #AEF1AE'>set(numCalibrationSamples, value)</span><span style=''>
</span>842 <span style=''>
</span>843 <span style=''>  def setInitMethod(value: String): this.type = </span><span style='background: #AEF1AE'>set(initMethod, value)</span><span style=''>
</span>844 <span style=''>
</span>845 <span style=''>  def setInitScale(value: Double): this.type = </span><span style='background: #AEF1AE'>set(initScale, value)</span><span style=''>
</span>846 <span style=''>
</span>847 <span style=''>  def setInitSigma(value: Double): this.type = </span><span style='background: #AEF1AE'>set(initSigma, value)</span><span style=''>
</span>848 <span style=''>
</span>849 <span style=''>  def setInitBias(value: Double): this.type = </span><span style='background: #AEF1AE'>set(initBias, value)</span><span style=''>
</span>850 <span style=''>
</span>851 <span style=''>  def setOptimizer(value: String): this.type = </span><span style='background: #AEF1AE'>set(optimizer, value)</span><span style=''>
</span>852 <span style=''>
</span>853 <span style=''>  def setLoss(value: String): this.type = </span><span style='background: #AEF1AE'>set(loss, value)</span><span style=''>
</span>854 <span style=''>
</span>855 <span style=''>  def setWd(value: Double): this.type = </span><span style='background: #AEF1AE'>set(wd, value)</span><span style=''>
</span>856 <span style=''>
</span>857 <span style=''>  def setL1(value: Double): this.type = </span><span style='background: #AEF1AE'>set(l1, value)</span><span style=''>
</span>858 <span style=''>
</span>859 <span style=''>  def setMomentum(value: Double): this.type = </span><span style='background: #AEF1AE'>set(momentum, value)</span><span style=''>
</span>860 <span style=''>
</span>861 <span style=''>  def setLearningRate(value: Double): this.type = </span><span style='background: #AEF1AE'>set(learningRate, value.toString)</span><span style=''>
</span>862 <span style=''>
</span>863 <span style=''>  def setLearningRate(value: String): this.type = </span><span style='background: #AEF1AE'>set(learningRate, value)</span><span style=''>
</span>864 <span style=''>
</span>865 <span style=''>  def setBeta1(value: Double): this.type = </span><span style='background: #AEF1AE'>set(beta1, value)</span><span style=''>
</span>866 <span style=''>
</span>867 <span style=''>  def setBeta2(value: Double): this.type = </span><span style='background: #AEF1AE'>set(beta2, value)</span><span style=''>
</span>868 <span style=''>
</span>869 <span style=''>  def setBiasLrMult(value: Double): this.type = </span><span style='background: #AEF1AE'>set(biasLrMult, value)</span><span style=''>
</span>870 <span style=''>
</span>871 <span style=''>  def setBiasWdMult(value: Double): this.type = </span><span style='background: #AEF1AE'>set(biasWdMult, value)</span><span style=''>
</span>872 <span style=''>
</span>873 <span style=''>  def setUseLrScheduler(value: Boolean): this.type = </span><span style='background: #AEF1AE'>set(useLrScheduler, value match {
</span>874 <span style=''></span><span style='background: #AEF1AE'>    case true =&gt; &quot;True&quot;
</span>875 <span style=''></span><span style='background: #AEF1AE'>    case false =&gt; &quot;False&quot;
</span>876 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>877 <span style=''>
</span>878 <span style=''>  def setLrSchedulerStep(value: Int): this.type = </span><span style='background: #AEF1AE'>set(lrSchedulerStep, value)</span><span style=''>
</span>879 <span style=''>
</span>880 <span style=''>  def setLrSchedulerFactor(value: Double): this.type = </span><span style='background: #AEF1AE'>set(lrSchedulerFactor, value)</span><span style=''>
</span>881 <span style=''>
</span>882 <span style=''>  def setLrSchedulerMinimumLr(value: Double): this.type = </span><span style='background: #AEF1AE'>set(lrSchedulerMinimumLr, value)</span><span style=''>
</span>883 <span style=''>
</span>884 <span style=''>  def setNormalizeData(value: Boolean): this.type = </span><span style='background: #AEF1AE'>set(normalizeData, value match {
</span>885 <span style=''></span><span style='background: #AEF1AE'>    case true =&gt; &quot;True&quot;
</span>886 <span style=''></span><span style='background: #AEF1AE'>    case false =&gt; &quot;False&quot;
</span>887 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>888 <span style=''>
</span>889 <span style=''>  def setNormalizeLabel(value: Boolean): this.type = </span><span style='background: #AEF1AE'>set(normalizeLabel, value match {
</span>890 <span style=''></span><span style='background: #AEF1AE'>    case true =&gt; &quot;True&quot;
</span>891 <span style=''></span><span style='background: #AEF1AE'>    case false =&gt; &quot;False&quot;
</span>892 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>893 <span style=''>
</span>894 <span style=''>  def setUnbiasData(value: Boolean): this.type = </span><span style='background: #AEF1AE'>set(unbiasData, value match {
</span>895 <span style=''></span><span style='background: #AEF1AE'>    case true =&gt; &quot;True&quot;
</span>896 <span style=''></span><span style='background: #AEF1AE'>    case false =&gt; &quot;False&quot;
</span>897 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>898 <span style=''>
</span>899 <span style=''>  def setUnbiasLabel(value: Boolean): this.type = </span><span style='background: #AEF1AE'>set(unbiasLabel, value match {
</span>900 <span style=''></span><span style='background: #AEF1AE'>    case true =&gt; &quot;True&quot;
</span>901 <span style=''></span><span style='background: #AEF1AE'>    case false =&gt; &quot;False&quot;
</span>902 <span style=''></span><span style='background: #AEF1AE'>  })</span><span style=''>
</span>903 <span style=''>
</span>904 <span style=''>  def setNumPointForScaler(value: Int): this.type = </span><span style='background: #AEF1AE'>set(numPointForScaler, value)</span><span style=''>
</span>905 <span style=''>
</span>906 <span style=''>  // Check whether required hyper-parameters are set
</span>907 <span style=''>  override def transformSchema(schema: StructType): StructType = {
</span>908 <span style=''>    </span><span style='background: #F0ADAD'>$(featureDim)</span><span style=''>
</span>909 <span style=''>    </span><span style='background: #F0ADAD'>$(predictorType)</span><span style=''>
</span>910 <span style=''>    </span><span style='background: #F0ADAD'>$(miniBatchSize)</span><span style=''>
</span>911 <span style=''>    </span><span style='background: #F0ADAD'>super.transformSchema(schema)</span><span style=''>
</span>912 <span style=''>  }
</span>913 <span style=''>
</span>914 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Code</th>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          730
        </td>
        <td>
          2601
          -
          3082
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;binary_classifier_model_selection_criteria&quot;, &quot;Pick the model with best criteria from the validation dataset for predictor_type = binary_classifier. Supported options: \'accuracy\', \'f1\', \'precision_at_target_recall\', \'recall_at_target_precision\' and \'cross_entropy_loss\'.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;accuracy&quot;, &quot;f1&quot;, &quot;precision_at_target_recall&quot;, &quot;recall_at_target_precision&quot;, &quot;cross_entropy_loss&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          51
        </td>
        <td>
          721
        </td>
        <td>
          2621
          -
          2665
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;binary_classifier_model_selection_criteria&quot;
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          722
        </td>
        <td>
          2671
          -
          2929
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Pick the model with best criteria from the validation dataset for predictor_type = binary_classifier. Supported options: \'accuracy\', \'f1\', \'precision_at_target_recall\', \'recall_at_target_precision\' and \'cross_entropy_loss\'.&quot;
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          729
        </td>
        <td>
          2935
          -
          3078
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;accuracy&quot;, &quot;f1&quot;, &quot;precision_at_target_recall&quot;, &quot;recall_at_target_precision&quot;, &quot;cross_entropy_loss&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          56
        </td>
        <td>
          728
        </td>
        <td>
          2959
          -
          3077
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;accuracy&quot;, &quot;f1&quot;, &quot;precision_at_target_recall&quot;, &quot;recall_at_target_precision&quot;, &quot;cross_entropy_loss&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          723
        </td>
        <td>
          2972
          -
          2982
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;accuracy&quot;
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          725
        </td>
        <td>
          2990
          -
          3018
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;precision_at_target_recall&quot;
        </td>
      </tr><tr>
        <td>
          57
        </td>
        <td>
          724
        </td>
        <td>
          2984
          -
          2988
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;f1&quot;
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          726
        </td>
        <td>
          3026
          -
          3054
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;recall_at_target_precision&quot;
        </td>
      </tr><tr>
        <td>
          58
        </td>
        <td>
          727
        </td>
        <td>
          3056
          -
          3076
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;cross_entropy_loss&quot;
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          732
        </td>
        <td>
          3141
          -
          3182
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          BinaryClassifierParams.this.$[String](BinaryClassifierParams.this.binaryClassifierModelSelectionCriteria)
        </td>
      </tr><tr>
        <td>
          60
        </td>
        <td>
          731
        </td>
        <td>
          3143
          -
          3181
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.BinaryClassifierParams.binaryClassifierModelSelectionCriteria
        </td>
        <td style="background: #AEF1AE">
          BinaryClassifierParams.this.binaryClassifierModelSelectionCriteria
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          733
        </td>
        <td>
          3417
          -
          3432
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;target_recall&quot;
        </td>
      </tr><tr>
        <td>
          67
        </td>
        <td>
          736
        </td>
        <td>
          3395
          -
          3636
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;target_recall&quot;, &quot;Applicable if binary_classifier_model_selection_criteria is precision_at_target_recall. Ignored otherwise. Must be in range (0, 1).&quot;, org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, false, false))
        </td>
      </tr><tr>
        <td>
          68
        </td>
        <td>
          734
        </td>
        <td>
          3438
          -
          3582
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Applicable if binary_classifier_model_selection_criteria is precision_at_target_recall. Ignored otherwise. Must be in range (0, 1).&quot;
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          735
        </td>
        <td>
          3588
          -
          3635
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inRange
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, false, false)
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          738
        </td>
        <td>
          3669
          -
          3684
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          BinaryClassifierParams.this.$[Double](BinaryClassifierParams.this.targetRecall)
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          737
        </td>
        <td>
          3671
          -
          3683
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.BinaryClassifierParams.targetRecall
        </td>
        <td style="background: #AEF1AE">
          BinaryClassifierParams.this.targetRecall
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          742
        </td>
        <td>
          3900
          -
          4144
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;target_precision&quot;, &quot;Applicable if binary_classifier_model_selection_criteria is recall_at_target_precision. Ignored otherwise. Must be in range (0, 1).&quot;, org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, false, false))
        </td>
      </tr><tr>
        <td>
          78
        </td>
        <td>
          739
        </td>
        <td>
          3922
          -
          3940
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;target_precision&quot;
        </td>
      </tr><tr>
        <td>
          79
        </td>
        <td>
          740
        </td>
        <td>
          3946
          -
          4090
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Applicable if binary_classifier_model_selection_criteria is recall_at_target_precision. Ignored otherwise. Must be in range (0, 1).&quot;
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          741
        </td>
        <td>
          4096
          -
          4143
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inRange
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, false, false)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          744
        </td>
        <td>
          4180
          -
          4198
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          BinaryClassifierParams.this.$[Double](BinaryClassifierParams.this.targetPrecision)
        </td>
      </tr><tr>
        <td>
          82
        </td>
        <td>
          743
        </td>
        <td>
          4182
          -
          4197
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.BinaryClassifierParams.targetPrecision
        </td>
        <td style="background: #AEF1AE">
          BinaryClassifierParams.this.targetPrecision
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          745
        </td>
        <td>
          4417
          -
          4425
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;epochs&quot;
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          748
        </td>
        <td>
          4398
          -
          4509
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.IntParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.IntParam(this, &quot;epochs&quot;, &quot;Max number of passes over the data. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          746
        </td>
        <td>
          4431
          -
          4481
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Max number of passes over the data. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          94
        </td>
        <td>
          747
        </td>
        <td>
          4487
          -
          4508
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          750
        </td>
        <td>
          4533
          -
          4542
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Int](LinearLearnerParams.this.epochs)
        </td>
      </tr><tr>
        <td>
          95
        </td>
        <td>
          749
        </td>
        <td>
          4535
          -
          4541
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.epochs
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.epochs
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          757
        </td>
        <td>
          4760
          -
          4997
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;predictor_type&quot;, &quot;Whether training is for binary classification or regression. Supported options: \'binary_classifier\', and \'regressor\'.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;binary_classifier&quot;, &quot;regressor&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          102
        </td>
        <td>
          751
        </td>
        <td>
          4776
          -
          4792
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;predictor_type&quot;
        </td>
      </tr><tr>
        <td>
          103
        </td>
        <td>
          752
        </td>
        <td>
          4798
          -
          4926
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether training is for binary classification or regression. Supported options: \'binary_classifier\', and \'regressor\'.&quot;
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          756
        </td>
        <td>
          4932
          -
          4996
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;binary_classifier&quot;, &quot;regressor&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          753
        </td>
        <td>
          4962
          -
          4981
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;binary_classifier&quot;
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          755
        </td>
        <td>
          4956
          -
          4995
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;binary_classifier&quot;, &quot;regressor&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          105
        </td>
        <td>
          754
        </td>
        <td>
          4983
          -
          4994
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;regressor&quot;
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          764
        </td>
        <td>
          5108
          -
          5231
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;use_bias&quot;, &quot;Whether model should include bias. &quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          111
        </td>
        <td>
          758
        </td>
        <td>
          5124
          -
          5134
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;use_bias&quot;
        </td>
      </tr><tr>
        <td>
          112
        </td>
        <td>
          759
        </td>
        <td>
          5140
          -
          5177
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether model should include bias. &quot;
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          762
        </td>
        <td>
          5207
          -
          5229
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          761
        </td>
        <td>
          5221
          -
          5228
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          760
        </td>
        <td>
          5213
          -
          5219
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          113
        </td>
        <td>
          763
        </td>
        <td>
          5183
          -
          5230
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          765
        </td>
        <td>
          5278
          -
          5285
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.useBias
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.useBias
        </td>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          766
        </td>
        <td>
          5260
          -
          5286
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.parseTrueAndFalse
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.parseTrueAndFalse(LinearLearnerParams.this.useBias)
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          770
        </td>
        <td>
          5549
          -
          5687
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;num_models&quot;, &quot;Number of models to train in parallel. Must be &gt; 0 or \'auto\'&quot;, LinearLearnerParams.this.autoOrAboveParamValidator(0.0, false))
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          767
        </td>
        <td>
          5565
          -
          5577
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;num_models&quot;
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          768
        </td>
        <td>
          5583
          -
          5645
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Number of models to train in parallel. Must be &gt; 0 or \'auto\'&quot;
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          769
        </td>
        <td>
          5651
          -
          5686
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.autoOrAboveParamValidator
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.autoOrAboveParamValidator(0.0, false)
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          771
        </td>
        <td>
          5719
          -
          5728
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numModels
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.numModels
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          772
        </td>
        <td>
          5717
          -
          5729
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[String](LinearLearnerParams.this.numModels)
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          773
        </td>
        <td>
          5961
          -
          5986
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;num_calibration_samples&quot;
        </td>
      </tr><tr>
        <td>
          132
        </td>
        <td>
          776
        </td>
        <td>
          5942
          -
          6152
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.IntParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.IntParam(this, &quot;num_calibration_samples&quot;, &quot;Number of samples to use from validation dataset for doing model calibration (finding the best threshold). Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          774
        </td>
        <td>
          5992
          -
          6124
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Number of samples to use from validation dataset for doing model calibration (finding the best threshold). Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          775
        </td>
        <td>
          6130
          -
          6151
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          777
        </td>
        <td>
          6193
          -
          6214
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numCalibrationSamples
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.numCalibrationSamples
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          778
        </td>
        <td>
          6191
          -
          6215
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Int](LinearLearnerParams.this.numCalibrationSamples)
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          779
        </td>
        <td>
          6496
          -
          6509
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;init_method&quot;
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          785
        </td>
        <td>
          6480
          -
          6664
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;init_method&quot;, &quot;Initialization function for the model weights. Supported options: \'uniform\' and \'normal\'.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;uniform&quot;, &quot;normal&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          780
        </td>
        <td>
          6515
          -
          6606
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Initialization function for the model weights. Supported options: \'uniform\' and \'normal\'.&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          783
        </td>
        <td>
          6636
          -
          6662
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;uniform&quot;, &quot;normal&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          782
        </td>
        <td>
          6653
          -
          6661
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;normal&quot;
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          784
        </td>
        <td>
          6612
          -
          6663
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;uniform&quot;, &quot;normal&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          781
        </td>
        <td>
          6642
          -
          6651
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;uniform&quot;
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          786
        </td>
        <td>
          6697
          -
          6707
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initMethod
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.initMethod
        </td>
      </tr><tr>
        <td>
          147
        </td>
        <td>
          787
        </td>
        <td>
          6695
          -
          6708
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[String](LinearLearnerParams.this.initMethod)
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          788
        </td>
        <td>
          6848
          -
          6860
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;init_scale&quot;
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          791
        </td>
        <td>
          6826
          -
          6939
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;init_scale&quot;, &quot;Scale for init method uniform. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          789
        </td>
        <td>
          6866
          -
          6911
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Scale for init method uniform. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          155
        </td>
        <td>
          790
        </td>
        <td>
          6917
          -
          6938
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          792
        </td>
        <td>
          6971
          -
          6980
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initScale
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.initScale
        </td>
      </tr><tr>
        <td>
          156
        </td>
        <td>
          793
        </td>
        <td>
          6969
          -
          6981
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.initScale)
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          797
        </td>
        <td>
          7111
          -
          7236
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;init_sigma&quot;, &quot;Standard deviation for init method normal. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          162
        </td>
        <td>
          794
        </td>
        <td>
          7133
          -
          7145
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;init_sigma&quot;
        </td>
      </tr><tr>
        <td>
          163
        </td>
        <td>
          795
        </td>
        <td>
          7151
          -
          7208
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Standard deviation for init method normal. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          796
        </td>
        <td>
          7214
          -
          7235
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          799
        </td>
        <td>
          7266
          -
          7278
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.initSigma)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          798
        </td>
        <td>
          7268
          -
          7277
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initSigma
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.initSigma
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          800
        </td>
        <td>
          7395
          -
          7406
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;init_bias&quot;
        </td>
      </tr><tr>
        <td>
          171
        </td>
        <td>
          802
        </td>
        <td>
          7373
          -
          7460
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;init_bias&quot;, &quot;Initial weight for bias. Must be number.&quot;)
        </td>
      </tr><tr>
        <td>
          172
        </td>
        <td>
          801
        </td>
        <td>
          7412
          -
          7459
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Initial weight for bias. Must be number.&quot;
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          804
        </td>
        <td>
          7489
          -
          7500
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.initBias)
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          803
        </td>
        <td>
          7491
          -
          7499
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initBias
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.initBias
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          806
        </td>
        <td>
          7675
          -
          7753
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Which optimizer is to be used. Supported options: \'sgd\' and \'adam\'.&quot;
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          811
        </td>
        <td>
          7646
          -
          7805
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;optimizer&quot;, &quot;Which optimizer is to be used. Supported options: \'sgd\' and \'adam\'.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;sgd&quot;, &quot;adam&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          805
        </td>
        <td>
          7662
          -
          7673
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;optimizer&quot;
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          810
        </td>
        <td>
          7759
          -
          7804
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;sgd&quot;, &quot;adam&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          809
        </td>
        <td>
          7783
          -
          7803
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;sgd&quot;, &quot;adam&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          808
        </td>
        <td>
          7796
          -
          7802
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;adam&quot;
        </td>
      </tr><tr>
        <td>
          181
        </td>
        <td>
          807
        </td>
        <td>
          7789
          -
          7794
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;sgd&quot;
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          813
        </td>
        <td>
          7835
          -
          7847
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[String](LinearLearnerParams.this.optimizer)
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          812
        </td>
        <td>
          7837
          -
          7846
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.optimizer
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.optimizer
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          821
        </td>
        <td>
          8006
          -
          8199
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;loss&quot;, &quot;The loss function to apply. Supported options: \'logistic\', \'squared_loss\' and \'auto\'.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;logistic&quot;, &quot;squared_loss&quot;, &quot;auto&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          815
        </td>
        <td>
          8030
          -
          8126
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;The loss function to apply. Supported options: \'logistic\', \'squared_loss\' and \'auto\'.&quot;
        </td>
      </tr><tr>
        <td>
          188
        </td>
        <td>
          814
        </td>
        <td>
          8022
          -
          8028
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;loss&quot;
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          819
        </td>
        <td>
          8156
          -
          8197
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;logistic&quot;, &quot;squared_loss&quot;, &quot;auto&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          818
        </td>
        <td>
          8190
          -
          8196
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;auto&quot;
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          817
        </td>
        <td>
          8174
          -
          8188
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;squared_loss&quot;
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          820
        </td>
        <td>
          8132
          -
          8198
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;logistic&quot;, &quot;squared_loss&quot;, &quot;auto&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          816
        </td>
        <td>
          8162
          -
          8172
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;logistic&quot;
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          822
        </td>
        <td>
          8226
          -
          8230
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.loss
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.loss
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          823
        </td>
        <td>
          8224
          -
          8231
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[String](LinearLearnerParams.this.loss)
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          824
        </td>
        <td>
          8425
          -
          8429
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;wd&quot;
        </td>
      </tr><tr>
        <td>
          198
        </td>
        <td>
          827
        </td>
        <td>
          8403
          -
          8536
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;wd&quot;, &quot;The L2 regularization, i.e. the weight decay parameter. Must be &gt;= 0.&quot;, org.apache.spark.ml.param.ParamValidators.gtEq[Any](0.0))
        </td>
      </tr><tr>
        <td>
          199
        </td>
        <td>
          825
        </td>
        <td>
          8435
          -
          8506
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;The L2 regularization, i.e. the weight decay parameter. Must be &gt;= 0.&quot;
        </td>
      </tr><tr>
        <td>
          200
        </td>
        <td>
          826
        </td>
        <td>
          8512
          -
          8535
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gtEq
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gtEq[Any](0.0)
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          828
        </td>
        <td>
          8561
          -
          8563
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.wd
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.wd
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          829
        </td>
        <td>
          8559
          -
          8564
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.wd)
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          830
        </td>
        <td>
          8729
          -
          8733
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;l1&quot;
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          833
        </td>
        <td>
          8707
          -
          8849
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;l1&quot;, &quot;The L1 regularization parameter. Use 0 for no L1 regularization. Must be &gt;= 0.&quot;, org.apache.spark.ml.param.ParamValidators.gtEq[Any](0.0))
        </td>
      </tr><tr>
        <td>
          208
        </td>
        <td>
          831
        </td>
        <td>
          8739
          -
          8819
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;The L1 regularization parameter. Use 0 for no L1 regularization. Must be &gt;= 0.&quot;
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          832
        </td>
        <td>
          8825
          -
          8848
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gtEq
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gtEq[Any](0.0)
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          835
        </td>
        <td>
          8872
          -
          8877
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.l1)
        </td>
      </tr><tr>
        <td>
          210
        </td>
        <td>
          834
        </td>
        <td>
          8874
          -
          8876
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.l1
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.l1
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          839
        </td>
        <td>
          9009
          -
          9163
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;momentum&quot;, &quot;Momentum parameter of sgd optimizer. Must be in range [0, 1).&quot;, org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, true, false))
        </td>
      </tr><tr>
        <td>
          216
        </td>
        <td>
          836
        </td>
        <td>
          9031
          -
          9041
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;momentum&quot;
        </td>
      </tr><tr>
        <td>
          217
        </td>
        <td>
          837
        </td>
        <td>
          9047
          -
          9110
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Momentum parameter of sgd optimizer. Must be in range [0, 1).&quot;
        </td>
      </tr><tr>
        <td>
          218
        </td>
        <td>
          838
        </td>
        <td>
          9116
          -
          9162
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inRange
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, true, false)
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          841
        </td>
        <td>
          9192
          -
          9203
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.momentum)
        </td>
      </tr><tr>
        <td>
          219
        </td>
        <td>
          840
        </td>
        <td>
          9194
          -
          9202
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.momentum
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.momentum
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          842
        </td>
        <td>
          9342
          -
          9357
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;learning_rate&quot;
        </td>
      </tr><tr>
        <td>
          225
        </td>
        <td>
          845
        </td>
        <td>
          9326
          -
          9447
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;learning_rate&quot;, &quot;The learning rate. Must be &gt; 0 or \'auto\'&quot;, LinearLearnerParams.this.autoOrAboveParamValidator(0.0, false))
        </td>
      </tr><tr>
        <td>
          226
        </td>
        <td>
          843
        </td>
        <td>
          9363
          -
          9405
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;The learning rate. Must be &gt; 0 or \'auto\'&quot;
        </td>
      </tr><tr>
        <td>
          227
        </td>
        <td>
          844
        </td>
        <td>
          9411
          -
          9446
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.autoOrAboveParamValidator
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.autoOrAboveParamValidator(0.0, false)
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          846
        </td>
        <td>
          9482
          -
          9494
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.learningRate
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.learningRate
        </td>
      </tr><tr>
        <td>
          228
        </td>
        <td>
          847
        </td>
        <td>
          9480
          -
          9495
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[String](LinearLearnerParams.this.learningRate)
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          848
        </td>
        <td>
          9742
          -
          9750
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;beta_1&quot;
        </td>
      </tr><tr>
        <td>
          235
        </td>
        <td>
          851
        </td>
        <td>
          9720
          -
          9971
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;beta_1&quot;, &quot;Parameter specific to adam optimizer. Exponential decay rate for first moment estimates. Ignored when optimizer is not adam. Must be in range [0, 1).&quot;, org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, true, false))
        </td>
      </tr><tr>
        <td>
          236
        </td>
        <td>
          849
        </td>
        <td>
          9756
          -
          9918
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter specific to adam optimizer. Exponential decay rate for first moment estimates. Ignored when optimizer is not adam. Must be in range [0, 1).&quot;
        </td>
      </tr><tr>
        <td>
          238
        </td>
        <td>
          850
        </td>
        <td>
          9924
          -
          9970
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inRange
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, true, false)
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          853
        </td>
        <td>
          9997
          -
          10005
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.beta1)
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          852
        </td>
        <td>
          9999
          -
          10004
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.beta1
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.beta1
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          857
        </td>
        <td>
          10233
          -
          10485
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;beta_2&quot;, &quot;Parameter specific to adam optimizer. exponential decay rate for second moment estimates. Ignored when optimizer is not adam. Must be in range [0, 1).&quot;, org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, true, false))
        </td>
      </tr><tr>
        <td>
          246
        </td>
        <td>
          854
        </td>
        <td>
          10255
          -
          10263
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;beta_2&quot;
        </td>
      </tr><tr>
        <td>
          247
        </td>
        <td>
          855
        </td>
        <td>
          10269
          -
          10432
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter specific to adam optimizer. exponential decay rate for second moment estimates. Ignored when optimizer is not adam. Must be in range [0, 1).&quot;
        </td>
      </tr><tr>
        <td>
          249
        </td>
        <td>
          856
        </td>
        <td>
          10438
          -
          10484
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inRange
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, true, false)
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          859
        </td>
        <td>
          10511
          -
          10519
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.beta2)
        </td>
      </tr><tr>
        <td>
          250
        </td>
        <td>
          858
        </td>
        <td>
          10513
          -
          10518
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.beta2
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.beta2
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          863
        </td>
        <td>
          10717
          -
          10925
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;bias_lr_mult&quot;, &quot;Learning rate bias multiplier. The actual learning rate for the bias is learning rate times bias_lr_mult. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          257
        </td>
        <td>
          860
        </td>
        <td>
          10739
          -
          10753
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;bias_lr_mult&quot;
        </td>
      </tr><tr>
        <td>
          259
        </td>
        <td>
          861
        </td>
        <td>
          10759
          -
          10901
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Learning rate bias multiplier. The actual learning rate for the bias is learning rate times bias_lr_mult. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          260
        </td>
        <td>
          862
        </td>
        <td>
          10903
          -
          10924
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          864
        </td>
        <td>
          10958
          -
          10968
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.biasLrMult
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.biasLrMult
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          865
        </td>
        <td>
          10956
          -
          10969
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.biasLrMult)
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          866
        </td>
        <td>
          11193
          -
          11207
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;bias_wd_mult&quot;
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          869
        </td>
        <td>
          11171
          -
          11386
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;bias_wd_mult&quot;, &quot;Weight decay parameter multiplier. The actual L2 regularization weight for the bias is wd times bias_wd_mult. Must be &gt;= 0.&quot;, org.apache.spark.ml.param.ParamValidators.gtEq[Any](0.0))
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          867
        </td>
        <td>
          11213
          -
          11360
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Weight decay parameter multiplier. The actual L2 regularization weight for the bias is wd times bias_wd_mult. Must be &gt;= 0.&quot;
        </td>
      </tr><tr>
        <td>
          271
        </td>
        <td>
          868
        </td>
        <td>
          11362
          -
          11385
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gtEq
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gtEq[Any](0.0)
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          871
        </td>
        <td>
          11417
          -
          11430
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.biasWdMult)
        </td>
      </tr><tr>
        <td>
          272
        </td>
        <td>
          870
        </td>
        <td>
          11419
          -
          11429
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.biasWdMult
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.biasWdMult
        </td>
      </tr><tr>
        <td>
          278
        </td>
        <td>
          872
        </td>
        <td>
          11576
          -
          11594
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;use_lr_scheduler&quot;
        </td>
      </tr><tr>
        <td>
          278
        </td>
        <td>
          878
        </td>
        <td>
          11560
          -
          11706
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;use_lr_scheduler&quot;, &quot;Whether to use a scheduler for the learning rate. &quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          279
        </td>
        <td>
          873
        </td>
        <td>
          11600
          -
          11652
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether to use a scheduler for the learning rate. &quot;
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          875
        </td>
        <td>
          11696
          -
          11703
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          877
        </td>
        <td>
          11658
          -
          11705
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          874
        </td>
        <td>
          11688
          -
          11694
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          280
        </td>
        <td>
          876
        </td>
        <td>
          11682
          -
          11704
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          281
        </td>
        <td>
          880
        </td>
        <td>
          11742
          -
          11775
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.parseTrueAndFalse
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.parseTrueAndFalse(LinearLearnerParams.this.useLrScheduler)
        </td>
      </tr><tr>
        <td>
          281
        </td>
        <td>
          879
        </td>
        <td>
          11760
          -
          11774
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.useLrScheduler
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.useLrScheduler
        </td>
      </tr><tr>
        <td>
          288
        </td>
        <td>
          881
        </td>
        <td>
          12004
          -
          12023
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;lr_scheduler_step&quot;
        </td>
      </tr><tr>
        <td>
          288
        </td>
        <td>
          884
        </td>
        <td>
          11985
          -
          12203
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.IntParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.IntParam(this, &quot;lr_scheduler_step&quot;, &quot;Parameter specific to lr_scheduler. Ignored otherwise.The number of steps between decreases of the learning rate. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          882
        </td>
        <td>
          12029
          -
          12179
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter specific to lr_scheduler. Ignored otherwise.The number of steps between decreases of the learning rate. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          291
        </td>
        <td>
          883
        </td>
        <td>
          12181
          -
          12202
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          292
        </td>
        <td>
          886
        </td>
        <td>
          12236
          -
          12254
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Int](LinearLearnerParams.this.lrSchedulerStep)
        </td>
      </tr><tr>
        <td>
          292
        </td>
        <td>
          885
        </td>
        <td>
          12238
          -
          12253
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.lrSchedulerStep
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.lrSchedulerStep
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          890
        </td>
        <td>
          12490
          -
          12755
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;lr_scheduler_factor&quot;, &quot;Parameter specific to lr_scheduler. Ignored otherwise.Every lr_scheduler_step the learning rate will decrease by this quantity. Must be in (0, 1).&quot;, org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, false, false))
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          887
        </td>
        <td>
          12512
          -
          12533
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;lr_scheduler_factor&quot;
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          888
        </td>
        <td>
          12539
          -
          12709
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter specific to lr_scheduler. Ignored otherwise.Every lr_scheduler_step the learning rate will decrease by this quantity. Must be in (0, 1).&quot;
        </td>
      </tr><tr>
        <td>
          302
        </td>
        <td>
          889
        </td>
        <td>
          12711
          -
          12754
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inRange
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inRange[Any](0.0, 1.0, false, false)
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          891
        </td>
        <td>
          12795
          -
          12812
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.lrSchedulerFactor
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.lrSchedulerFactor
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          892
        </td>
        <td>
          12793
          -
          12813
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.lrSchedulerFactor)
        </td>
      </tr><tr>
        <td>
          311
        </td>
        <td>
          893
        </td>
        <td>
          13085
          -
          13110
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;lr_scheduler_minimum_lr&quot;
        </td>
      </tr><tr>
        <td>
          311
        </td>
        <td>
          896
        </td>
        <td>
          13063
          -
          13315
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.DoubleParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.DoubleParam(this, &quot;lr_scheduler_minimum_lr&quot;, &quot;Parameter specific to lr_scheduler. Ignored otherwise.The learning rate will never decrease to a value lower than lr_scheduler_minimum_lr. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          313
        </td>
        <td>
          894
        </td>
        <td>
          13116
          -
          13291
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Parameter specific to lr_scheduler. Ignored otherwise.The learning rate will never decrease to a value lower than lr_scheduler_minimum_lr. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          314
        </td>
        <td>
          895
        </td>
        <td>
          13293
          -
          13314
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          898
        </td>
        <td>
          13356
          -
          13379
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Double](LinearLearnerParams.this.lrSchedulerMinimumLr)
        </td>
      </tr><tr>
        <td>
          315
        </td>
        <td>
          897
        </td>
        <td>
          13358
          -
          13378
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.lrSchedulerMinimumLr
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.lrSchedulerMinimumLr
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          899
        </td>
        <td>
          13546
          -
          13562
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;normalize_data&quot;
        </td>
      </tr><tr>
        <td>
          321
        </td>
        <td>
          905
        </td>
        <td>
          13530
          -
          13696
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;normalize_data&quot;, &quot;Whether to normalize the features before training to have std_dev of 1. &quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          322
        </td>
        <td>
          900
        </td>
        <td>
          13568
          -
          13642
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether to normalize the features before training to have std_dev of 1. &quot;
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          902
        </td>
        <td>
          13686
          -
          13693
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          904
        </td>
        <td>
          13648
          -
          13695
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          901
        </td>
        <td>
          13678
          -
          13684
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          323
        </td>
        <td>
          903
        </td>
        <td>
          13672
          -
          13694
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          907
        </td>
        <td>
          13731
          -
          13763
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.parseTrueAndFalse
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.parseTrueAndFalse(LinearLearnerParams.this.normalizeData)
        </td>
      </tr><tr>
        <td>
          324
        </td>
        <td>
          906
        </td>
        <td>
          13749
          -
          13762
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.normalizeData
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.normalizeData
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          908
        </td>
        <td>
          13928
          -
          13945
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;normalize_label&quot;
        </td>
      </tr><tr>
        <td>
          330
        </td>
        <td>
          914
        </td>
        <td>
          13912
          -
          14093
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;normalize_label&quot;, &quot;Whether regression label is normalized. If set for classification, it will be ignored.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          909
        </td>
        <td>
          13951
          -
          14039
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether regression label is normalized. If set for classification, it will be ignored.&quot;
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          911
        </td>
        <td>
          14083
          -
          14090
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          913
        </td>
        <td>
          14045
          -
          14092
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          910
        </td>
        <td>
          14075
          -
          14081
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          912
        </td>
        <td>
          14069
          -
          14091
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          333
        </td>
        <td>
          916
        </td>
        <td>
          14129
          -
          14162
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.parseTrueAndFalse
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.parseTrueAndFalse(LinearLearnerParams.this.normalizeLabel)
        </td>
      </tr><tr>
        <td>
          333
        </td>
        <td>
          915
        </td>
        <td>
          14147
          -
          14161
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.normalizeLabel
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.normalizeLabel
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          923
        </td>
        <td>
          14368
          -
          14591
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;unbias_data&quot;, &quot;Whether to unbias the features before training so that mean is 0. By default data is unbiased if use_bias is set to true.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          340
        </td>
        <td>
          917
        </td>
        <td>
          14384
          -
          14397
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;unbias_data&quot;
        </td>
      </tr><tr>
        <td>
          341
        </td>
        <td>
          918
        </td>
        <td>
          14403
          -
          14537
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether to unbias the features before training so that mean is 0. By default data is unbiased if use_bias is set to true.&quot;
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          920
        </td>
        <td>
          14581
          -
          14588
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          922
        </td>
        <td>
          14543
          -
          14590
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          919
        </td>
        <td>
          14573
          -
          14579
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          343
        </td>
        <td>
          921
        </td>
        <td>
          14567
          -
          14589
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          344
        </td>
        <td>
          925
        </td>
        <td>
          14623
          -
          14652
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.parseTrueAndFalse
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.parseTrueAndFalse(LinearLearnerParams.this.unbiasData)
        </td>
      </tr><tr>
        <td>
          344
        </td>
        <td>
          924
        </td>
        <td>
          14641
          -
          14651
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.unbiasData
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.unbiasData
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          932
        </td>
        <td>
          14873
          -
          15111
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.Param[String](this, &quot;unbias_label&quot;, &quot;Whether to unbias the labels before training so that mean is 0. Only done for regrssion if use_bias is true. Otherwise will be ignored.&quot;, org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))))
        </td>
      </tr><tr>
        <td>
          351
        </td>
        <td>
          926
        </td>
        <td>
          14889
          -
          14903
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;unbias_label&quot;
        </td>
      </tr><tr>
        <td>
          352
        </td>
        <td>
          927
        </td>
        <td>
          14909
          -
          15057
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Whether to unbias the labels before training so that mean is 0. Only done for regrssion if use_bias is true. Otherwise will be ignored.&quot;
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          929
        </td>
        <td>
          15101
          -
          15108
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          931
        </td>
        <td>
          15063
          -
          15110
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.inArray
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.inArray[String](scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String])))
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          928
        </td>
        <td>
          15093
          -
          15099
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          354
        </td>
        <td>
          930
        </td>
        <td>
          15087
          -
          15109
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.Array.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Array.apply[String](&quot;True&quot;, &quot;False&quot;)((ClassTag.apply[String](classOf[java.lang.String]): scala.reflect.ClassTag[String]))
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          934
        </td>
        <td>
          15144
          -
          15174
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.parseTrueAndFalse
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.parseTrueAndFalse(LinearLearnerParams.this.unbiasLabel)
        </td>
      </tr><tr>
        <td>
          355
        </td>
        <td>
          933
        </td>
        <td>
          15162
          -
          15173
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.unbiasLabel
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.unbiasLabel
        </td>
      </tr><tr>
        <td>
          361
        </td>
        <td>
          935
        </td>
        <td>
          15365
          -
          15387
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;num_point_for_scaler&quot;
        </td>
      </tr><tr>
        <td>
          361
        </td>
        <td>
          938
        </td>
        <td>
          15346
          -
          15521
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.IntParam.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new org.apache.spark.ml.param.IntParam(this, &quot;num_point_for_scaler&quot;, &quot;Number of data points to use for calcuating the normalizing / unbiasing terms. Must be &gt; 0.&quot;, org.apache.spark.ml.param.ParamValidators.gt[Any](0.0))
        </td>
      </tr><tr>
        <td>
          362
        </td>
        <td>
          936
        </td>
        <td>
          15393
          -
          15497
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;Number of data points to use for calcuating the normalizing / unbiasing terms. Must be &gt; 0.&quot;
        </td>
      </tr><tr>
        <td>
          363
        </td>
        <td>
          937
        </td>
        <td>
          15499
          -
          15520
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.ParamValidators.gt
        </td>
        <td style="background: #AEF1AE">
          org.apache.spark.ml.param.ParamValidators.gt[Any](0.0)
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          940
        </td>
        <td>
          15556
          -
          15576
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.$[Int](LinearLearnerParams.this.numPointForScaler)
        </td>
      </tr><tr>
        <td>
          364
        </td>
        <td>
          939
        </td>
        <td>
          15558
          -
          15575
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numPointForScaler
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerParams.this.numPointForScaler
        </td>
      </tr><tr>
        <td>
          368
        </td>
        <td>
          941
        </td>
        <td>
          15643
          -
          15659
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;linear-learner&quot;
        </td>
      </tr><tr>
        <td>
          369
        </td>
        <td>
          942
        </td>
        <td>
          15681
          -
          15684
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;1&quot;
        </td>
      </tr><tr>
        <td>
          370
        </td>
        <td>
          943
        </td>
        <td>
          15710
          -
          15758
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SagerMakerRegionAccountMaps.AlgorithmsAccountMap
        </td>
        <td style="background: #AEF1AE">
          SagerMakerRegionAccountMaps.AlgorithmsAccountMap
        </td>
      </tr><tr>
        <td>
          514
        </td>
        <td>
          944
        </td>
        <td>
          24647
          -
          24683
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.-&gt;
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.predictorType.-&gt;(&quot;binary_classifier&quot;)
        </td>
      </tr><tr>
        <td>
          514
        </td>
        <td>
          945
        </td>
        <td>
          24636
          -
          24684
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.setDefault
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.setDefault(LinearLearnerBinaryClassifier.this.predictorType.-&gt;(&quot;binary_classifier&quot;))
        </td>
      </tr><tr>
        <td>
          517
        </td>
        <td>
          947
        </td>
        <td>
          24766
          -
          24816
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.set[String](LinearLearnerBinaryClassifier.this.binaryClassifierModelSelectionCriteria, value)
        </td>
      </tr><tr>
        <td>
          517
        </td>
        <td>
          946
        </td>
        <td>
          24770
          -
          24808
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.BinaryClassifierParams.binaryClassifierModelSelectionCriteria
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.binaryClassifierModelSelectionCriteria
        </td>
      </tr><tr>
        <td>
          519
        </td>
        <td>
          949
        </td>
        <td>
          24868
          -
          24892
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.set[Double](LinearLearnerBinaryClassifier.this.targetRecall, value)
        </td>
      </tr><tr>
        <td>
          519
        </td>
        <td>
          948
        </td>
        <td>
          24872
          -
          24884
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.BinaryClassifierParams.targetRecall
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.targetRecall
        </td>
      </tr><tr>
        <td>
          521
        </td>
        <td>
          950
        </td>
        <td>
          24951
          -
          24966
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.BinaryClassifierParams.targetPrecision
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.targetPrecision
        </td>
      </tr><tr>
        <td>
          521
        </td>
        <td>
          951
        </td>
        <td>
          24947
          -
          24974
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerBinaryClassifier.this.set[Double](LinearLearnerBinaryClassifier.this.targetPrecision, value)
        </td>
      </tr><tr>
        <td>
          670
        </td>
        <td>
          953
        </td>
        <td>
          34304
          -
          34344
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.setDefault
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerRegressor.this.setDefault(LinearLearnerRegressor.this.predictorType.-&gt;(&quot;regressor&quot;))
        </td>
      </tr><tr>
        <td>
          670
        </td>
        <td>
          952
        </td>
        <td>
          34315
          -
          34343
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.-&gt;
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerRegressor.this.predictorType.-&gt;(&quot;regressor&quot;)
        </td>
      </tr><tr>
        <td>
          824
        </td>
        <td>
          955
        </td>
        <td>
          44273
          -
          44306
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.setDefault
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.setDefault(LinearLearnerSageMakerEstimator.this.miniBatchSize.-&gt;(1000))
        </td>
      </tr><tr>
        <td>
          824
        </td>
        <td>
          954
        </td>
        <td>
          44284
          -
          44305
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Param.-&gt;
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.miniBatchSize.-&gt;(1000)
        </td>
      </tr><tr>
        <td>
          826
        </td>
        <td>
          956
        </td>
        <td>
          44357
          -
          44367
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.featureDim
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.featureDim
        </td>
      </tr><tr>
        <td>
          826
        </td>
        <td>
          957
        </td>
        <td>
          44353
          -
          44375
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Int](LinearLearnerSageMakerEstimator.this.featureDim, value)
        </td>
      </tr><tr>
        <td>
          828
        </td>
        <td>
          959
        </td>
        <td>
          44425
          -
          44450
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Int](LinearLearnerSageMakerEstimator.this.miniBatchSize, value)
        </td>
      </tr><tr>
        <td>
          828
        </td>
        <td>
          958
        </td>
        <td>
          44429
          -
          44442
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.miniBatchSize
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.miniBatchSize
        </td>
      </tr><tr>
        <td>
          830
        </td>
        <td>
          961
        </td>
        <td>
          44493
          -
          44511
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Int](LinearLearnerSageMakerEstimator.this.epochs, value)
        </td>
      </tr><tr>
        <td>
          830
        </td>
        <td>
          960
        </td>
        <td>
          44497
          -
          44503
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.epochs
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.epochs
        </td>
      </tr><tr>
        <td>
          832
        </td>
        <td>
          962
        </td>
        <td>
          44563
          -
          44570
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.useBias
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.useBias
        </td>
      </tr><tr>
        <td>
          832
        </td>
        <td>
          965
        </td>
        <td>
          44559
          -
          44640
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.useBias, value match {
  case true =&gt; &quot;True&quot;
  case false =&gt; &quot;False&quot;
})
        </td>
      </tr><tr>
        <td>
          833
        </td>
        <td>
          963
        </td>
        <td>
          44603
          -
          44609
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          834
        </td>
        <td>
          964
        </td>
        <td>
          44628
          -
          44635
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          837
        </td>
        <td>
          968
        </td>
        <td>
          44686
          -
          44716
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.numModels, value.toString())
        </td>
      </tr><tr>
        <td>
          837
        </td>
        <td>
          967
        </td>
        <td>
          44701
          -
          44715
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.toString
        </td>
        <td style="background: #AEF1AE">
          value.toString()
        </td>
      </tr><tr>
        <td>
          837
        </td>
        <td>
          966
        </td>
        <td>
          44690
          -
          44699
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numModels
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.numModels
        </td>
      </tr><tr>
        <td>
          839
        </td>
        <td>
          970
        </td>
        <td>
          44765
          -
          44786
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.numModels, value)
        </td>
      </tr><tr>
        <td>
          839
        </td>
        <td>
          969
        </td>
        <td>
          44769
          -
          44778
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numModels
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.numModels
        </td>
      </tr><tr>
        <td>
          841
        </td>
        <td>
          971
        </td>
        <td>
          44848
          -
          44869
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numCalibrationSamples
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.numCalibrationSamples
        </td>
      </tr><tr>
        <td>
          841
        </td>
        <td>
          972
        </td>
        <td>
          44844
          -
          44877
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Int](LinearLearnerSageMakerEstimator.this.numCalibrationSamples, value)
        </td>
      </tr><tr>
        <td>
          843
        </td>
        <td>
          974
        </td>
        <td>
          44927
          -
          44949
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.initMethod, value)
        </td>
      </tr><tr>
        <td>
          843
        </td>
        <td>
          973
        </td>
        <td>
          44931
          -
          44941
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initMethod
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.initMethod
        </td>
      </tr><tr>
        <td>
          845
        </td>
        <td>
          976
        </td>
        <td>
          44998
          -
          45019
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.initScale, value)
        </td>
      </tr><tr>
        <td>
          845
        </td>
        <td>
          975
        </td>
        <td>
          45002
          -
          45011
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initScale
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.initScale
        </td>
      </tr><tr>
        <td>
          847
        </td>
        <td>
          977
        </td>
        <td>
          45072
          -
          45081
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initSigma
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.initSigma
        </td>
      </tr><tr>
        <td>
          847
        </td>
        <td>
          978
        </td>
        <td>
          45068
          -
          45089
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.initSigma, value)
        </td>
      </tr><tr>
        <td>
          849
        </td>
        <td>
          980
        </td>
        <td>
          45137
          -
          45157
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.initBias, value)
        </td>
      </tr><tr>
        <td>
          849
        </td>
        <td>
          979
        </td>
        <td>
          45141
          -
          45149
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.initBias
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.initBias
        </td>
      </tr><tr>
        <td>
          851
        </td>
        <td>
          982
        </td>
        <td>
          45206
          -
          45227
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.optimizer, value)
        </td>
      </tr><tr>
        <td>
          851
        </td>
        <td>
          981
        </td>
        <td>
          45210
          -
          45219
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.optimizer
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.optimizer
        </td>
      </tr><tr>
        <td>
          853
        </td>
        <td>
          983
        </td>
        <td>
          45275
          -
          45279
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.loss
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.loss
        </td>
      </tr><tr>
        <td>
          853
        </td>
        <td>
          984
        </td>
        <td>
          45271
          -
          45287
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.loss, value)
        </td>
      </tr><tr>
        <td>
          855
        </td>
        <td>
          986
        </td>
        <td>
          45329
          -
          45343
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.wd, value)
        </td>
      </tr><tr>
        <td>
          855
        </td>
        <td>
          985
        </td>
        <td>
          45333
          -
          45335
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.wd
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.wd
        </td>
      </tr><tr>
        <td>
          857
        </td>
        <td>
          988
        </td>
        <td>
          45385
          -
          45399
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.l1, value)
        </td>
      </tr><tr>
        <td>
          857
        </td>
        <td>
          987
        </td>
        <td>
          45389
          -
          45391
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.l1
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.l1
        </td>
      </tr><tr>
        <td>
          859
        </td>
        <td>
          989
        </td>
        <td>
          45451
          -
          45459
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.momentum
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.momentum
        </td>
      </tr><tr>
        <td>
          859
        </td>
        <td>
          990
        </td>
        <td>
          45447
          -
          45467
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.momentum, value)
        </td>
      </tr><tr>
        <td>
          861
        </td>
        <td>
          992
        </td>
        <td>
          45537
          -
          45551
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Any.toString
        </td>
        <td style="background: #AEF1AE">
          value.toString()
        </td>
      </tr><tr>
        <td>
          861
        </td>
        <td>
          991
        </td>
        <td>
          45523
          -
          45535
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.learningRate
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.learningRate
        </td>
      </tr><tr>
        <td>
          861
        </td>
        <td>
          993
        </td>
        <td>
          45519
          -
          45552
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.learningRate, value.toString())
        </td>
      </tr><tr>
        <td>
          863
        </td>
        <td>
          995
        </td>
        <td>
          45604
          -
          45628
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.learningRate, value)
        </td>
      </tr><tr>
        <td>
          863
        </td>
        <td>
          994
        </td>
        <td>
          45608
          -
          45620
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.learningRate
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.learningRate
        </td>
      </tr><tr>
        <td>
          865
        </td>
        <td>
          997
        </td>
        <td>
          45673
          -
          45690
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.beta1, value)
        </td>
      </tr><tr>
        <td>
          865
        </td>
        <td>
          996
        </td>
        <td>
          45677
          -
          45682
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.beta1
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.beta1
        </td>
      </tr><tr>
        <td>
          867
        </td>
        <td>
          998
        </td>
        <td>
          45739
          -
          45744
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.beta2
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.beta2
        </td>
      </tr><tr>
        <td>
          867
        </td>
        <td>
          999
        </td>
        <td>
          45735
          -
          45752
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.beta2, value)
        </td>
      </tr><tr>
        <td>
          869
        </td>
        <td>
          1001
        </td>
        <td>
          45802
          -
          45824
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.biasLrMult, value)
        </td>
      </tr><tr>
        <td>
          869
        </td>
        <td>
          1000
        </td>
        <td>
          45806
          -
          45816
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.biasLrMult
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.biasLrMult
        </td>
      </tr><tr>
        <td>
          871
        </td>
        <td>
          1003
        </td>
        <td>
          45874
          -
          45896
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.biasWdMult, value)
        </td>
      </tr><tr>
        <td>
          871
        </td>
        <td>
          1002
        </td>
        <td>
          45878
          -
          45888
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.biasWdMult
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.biasWdMult
        </td>
      </tr><tr>
        <td>
          873
        </td>
        <td>
          1004
        </td>
        <td>
          45955
          -
          45969
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.useLrScheduler
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.useLrScheduler
        </td>
      </tr><tr>
        <td>
          873
        </td>
        <td>
          1007
        </td>
        <td>
          45951
          -
          46039
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.useLrScheduler, value match {
  case true =&gt; &quot;True&quot;
  case false =&gt; &quot;False&quot;
})
        </td>
      </tr><tr>
        <td>
          874
        </td>
        <td>
          1005
        </td>
        <td>
          46002
          -
          46008
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          875
        </td>
        <td>
          1006
        </td>
        <td>
          46027
          -
          46034
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          878
        </td>
        <td>
          1009
        </td>
        <td>
          46091
          -
          46118
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Int](LinearLearnerSageMakerEstimator.this.lrSchedulerStep, value)
        </td>
      </tr><tr>
        <td>
          878
        </td>
        <td>
          1008
        </td>
        <td>
          46095
          -
          46110
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.lrSchedulerStep
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.lrSchedulerStep
        </td>
      </tr><tr>
        <td>
          880
        </td>
        <td>
          1010
        </td>
        <td>
          46179
          -
          46196
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.lrSchedulerFactor
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.lrSchedulerFactor
        </td>
      </tr><tr>
        <td>
          880
        </td>
        <td>
          1011
        </td>
        <td>
          46175
          -
          46204
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.lrSchedulerFactor, value)
        </td>
      </tr><tr>
        <td>
          882
        </td>
        <td>
          1013
        </td>
        <td>
          46264
          -
          46296
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Double](LinearLearnerSageMakerEstimator.this.lrSchedulerMinimumLr, value)
        </td>
      </tr><tr>
        <td>
          882
        </td>
        <td>
          1012
        </td>
        <td>
          46268
          -
          46288
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.lrSchedulerMinimumLr
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.lrSchedulerMinimumLr
        </td>
      </tr><tr>
        <td>
          884
        </td>
        <td>
          1014
        </td>
        <td>
          46354
          -
          46367
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.normalizeData
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.normalizeData
        </td>
      </tr><tr>
        <td>
          884
        </td>
        <td>
          1017
        </td>
        <td>
          46350
          -
          46437
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.normalizeData, value match {
  case true =&gt; &quot;True&quot;
  case false =&gt; &quot;False&quot;
})
        </td>
      </tr><tr>
        <td>
          885
        </td>
        <td>
          1015
        </td>
        <td>
          46400
          -
          46406
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          886
        </td>
        <td>
          1016
        </td>
        <td>
          46425
          -
          46432
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          889
        </td>
        <td>
          1018
        </td>
        <td>
          46496
          -
          46510
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.normalizeLabel
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.normalizeLabel
        </td>
      </tr><tr>
        <td>
          889
        </td>
        <td>
          1021
        </td>
        <td>
          46492
          -
          46580
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.normalizeLabel, value match {
  case true =&gt; &quot;True&quot;
  case false =&gt; &quot;False&quot;
})
        </td>
      </tr><tr>
        <td>
          890
        </td>
        <td>
          1019
        </td>
        <td>
          46543
          -
          46549
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          891
        </td>
        <td>
          1020
        </td>
        <td>
          46568
          -
          46575
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          894
        </td>
        <td>
          1022
        </td>
        <td>
          46635
          -
          46645
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.unbiasData
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.unbiasData
        </td>
      </tr><tr>
        <td>
          894
        </td>
        <td>
          1025
        </td>
        <td>
          46631
          -
          46715
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.unbiasData, value match {
  case true =&gt; &quot;True&quot;
  case false =&gt; &quot;False&quot;
})
        </td>
      </tr><tr>
        <td>
          895
        </td>
        <td>
          1023
        </td>
        <td>
          46678
          -
          46684
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          896
        </td>
        <td>
          1024
        </td>
        <td>
          46703
          -
          46710
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          899
        </td>
        <td>
          1029
        </td>
        <td>
          46767
          -
          46852
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[String](LinearLearnerSageMakerEstimator.this.unbiasLabel, value match {
  case true =&gt; &quot;True&quot;
  case false =&gt; &quot;False&quot;
})
        </td>
      </tr><tr>
        <td>
          899
        </td>
        <td>
          1026
        </td>
        <td>
          46771
          -
          46782
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.unbiasLabel
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.unbiasLabel
        </td>
      </tr><tr>
        <td>
          900
        </td>
        <td>
          1027
        </td>
        <td>
          46815
          -
          46821
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;True&quot;
        </td>
      </tr><tr>
        <td>
          901
        </td>
        <td>
          1028
        </td>
        <td>
          46840
          -
          46847
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;False&quot;
        </td>
      </tr><tr>
        <td>
          904
        </td>
        <td>
          1031
        </td>
        <td>
          46906
          -
          46935
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.set
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.set[Int](LinearLearnerSageMakerEstimator.this.numPointForScaler, value)
        </td>
      </tr><tr>
        <td>
          904
        </td>
        <td>
          1030
        </td>
        <td>
          46910
          -
          46927
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.numPointForScaler
        </td>
        <td style="background: #AEF1AE">
          LinearLearnerSageMakerEstimator.this.numPointForScaler
        </td>
      </tr><tr>
        <td>
          908
        </td>
        <td>
          1033
        </td>
        <td>
          47061
          -
          47074
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.this.$[Int](LinearLearnerSageMakerEstimator.this.featureDim)
        </td>
      </tr><tr>
        <td>
          908
        </td>
        <td>
          1032
        </td>
        <td>
          47063
          -
          47073
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.featureDim
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.this.featureDim
        </td>
      </tr><tr>
        <td>
          909
        </td>
        <td>
          1034
        </td>
        <td>
          47081
          -
          47094
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.LinearLearnerParams.predictorType
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.this.predictorType
        </td>
      </tr><tr>
        <td>
          909
        </td>
        <td>
          1035
        </td>
        <td>
          47079
          -
          47095
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.this.$[String](LinearLearnerSageMakerEstimator.this.predictorType)
        </td>
      </tr><tr>
        <td>
          910
        </td>
        <td>
          1037
        </td>
        <td>
          47100
          -
          47116
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.ml.param.Params.$
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.this.$[Int](LinearLearnerSageMakerEstimator.this.miniBatchSize)
        </td>
      </tr><tr>
        <td>
          910
        </td>
        <td>
          1036
        </td>
        <td>
          47102
          -
          47115
        </td>
        <td>
          Select
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.algorithms.SageMakerAlgorithmParams.miniBatchSize
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.this.miniBatchSize
        </td>
      </tr><tr>
        <td>
          911
        </td>
        <td>
          1038
        </td>
        <td>
          47121
          -
          47150
        </td>
        <td>
          Apply
        </td>
        <td>
          com.amazonaws.services.sagemaker.sparksdk.SageMakerEstimator.transformSchema
        </td>
        <td style="background: #F0ADAD">
          LinearLearnerSageMakerEstimator.super.transformSchema(schema)
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>